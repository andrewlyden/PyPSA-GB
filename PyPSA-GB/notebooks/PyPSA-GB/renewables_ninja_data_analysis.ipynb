{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b1f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"renewables time series script\n",
    "\n",
    "contains functions for interacting with renewables ninja API\n",
    "and fixing these. Also contains functions for introducing correction\n",
    "factors based upon reported historical renewable generation. This has\n",
    "scope for improvement as it currently involves a linear correction factor\n",
    "which is flat across the timeseries and locations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcba6616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6951c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import renewables\n",
    "import renewables_ninja_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fa8bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_PV():\n",
    "    \"\"\"for joining time series pickle files together\n",
    "    \"\"\"\n",
    "\n",
    "    # # # read in the PV files\n",
    "    # df = pickle.load(open(\"data/renewables/2016/onshore_time_series.pkl\", \"rb\"))\n",
    "    # print(df)\n",
    "    # df2 = pickle.load(open(\"data/renewables/2016/onshore_time_series2.pkl\", \"rb\"))\n",
    "    # print(df2)\n",
    "    # # # df3 = pickle.load(open(\"data/renewables/2018/PV_time_series_norm3.pkl\", \"rb\"))\n",
    "    # # # print(df2)\n",
    "    # # # join the two dataframes\n",
    "    # result = pd.concat([df, df2], axis=1)\n",
    "    # print(result)\n",
    "\n",
    "    # year = 2019\n",
    "    # # read in the renewables dataframe\n",
    "    # df = data_reader_writer.REPD_date_corrected(year)\n",
    "    # df_pv = df.loc[df['Technology Type'] == 'Solar Photovoltaics'].reset_index(drop=True)\n",
    "    # print(df_pv)\n",
    "\n",
    "    # z = result.columns.to_list()\n",
    "    # item = df_pv['Site Name'].to_list()\n",
    "    # not_in_list = [x for x in item if x not in z]\n",
    "    # print(not_in_list)\n",
    "    # print(len(not_in_list))\n",
    "    # result = result.reset_index().T.drop_duplicates().T\n",
    "    # print(result)\n",
    "\n",
    "    meta = pickle.load(open(\"data/renewables/2016/onshore_metadata.pkl\", \"rb\"))\n",
    "    print(len(meta))\n",
    "    meta2 = pickle.load(open(\"data/renewables/2016/onshore_metadata2.pkl\", \"rb\"))\n",
    "    print(len(meta2))\n",
    "\n",
    "    meta.update(meta2)\n",
    "    print(len(meta))\n",
    "\n",
    "    # save the new dataframe\n",
    "    # result.to_pickle(\"data/renewables/2016/onshore_time_series_norm.pkl\")\n",
    "    # result.to_pickle(\"data/renewables/2016/onshore_time_series.pkl\")\n",
    "    with open('data/renewables/2016/onshore_metadata.pkl', 'wb') as handle:\n",
    "        pickle.dump(\n",
    "            meta, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151544c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offshore_wind_time_series(df, year, date_from, date_to):\n",
    "    \"\"\"offshore wind time series download from renewables ninja\n",
    "\n",
    "    writes the timeseries to pickle file in relevant folder\n",
    "    note that only single year can be accessed\n",
    "\n",
    "   Parameters\n",
    "    ----------\n",
    "    df : dataframe\n",
    "        REPD data, should use date corrected version\n",
    "    year: int/str\n",
    "        Year of simulation\n",
    "    date_from: str\n",
    "        time series date from\n",
    "    date_to: str\n",
    "        time series date to\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "\n",
    "    # aim is to extract power series for\n",
    "    # offshore wind farms from renewables.ninja\n",
    "    df_offshore_wind = df.loc[df['Technology Type'] == 'Wind Offshore']\n",
    "    df_offshore_wind = df_offshore_wind.reset_index()\n",
    "\n",
    "    # check that data is available\n",
    "    if df_offshore_wind['No. of Turbines'].isnull().values.any() == True:\n",
    "        raise Exception(\"Number of turbines values must be provided, please fill in missing data in csv file\")\n",
    "    if df_offshore_wind['Turbine Capacity (MW)'].isnull().values.any() == True:\n",
    "        raise Exception(\"Number of turbines values must be provided, please fill in missing data in csv file\")\n",
    "\n",
    "    output_series = []\n",
    "    output_series_normalised = []\n",
    "    output_series_metadata = {}\n",
    "\n",
    "    length = df_offshore_wind.index\n",
    "    # length = range(3)\n",
    "    print(length, ' number of requests.')\n",
    "    for i in range(len(length)):\n",
    "\n",
    "        print(i)\n",
    "        print(df_offshore_wind['Site Name'][i])\n",
    "\n",
    "        # multiplied by 1000 to convert to kW\n",
    "        capacity = df_offshore_wind['Turbine Capacity (MW)'][i] * 1000\n",
    "\n",
    "        # check if height given\n",
    "        if df_offshore_wind['Height of Turbines (m)'][i] == 'NaN':\n",
    "            height = df_offshore_wind['Height of Turbines (m)'][i]\n",
    "        else:\n",
    "            # need to estimate height from turbine capacity using regression\n",
    "            height = wind_hub_height_to_capacity_regression(\n",
    "                capacity)\n",
    "\n",
    "        # height is limited to 150m\n",
    "        height = min(height, 150)\n",
    "\n",
    "        # need to figure out which turbine to use for power curve\n",
    "        # vestas has a wide range, let just use their ones\n",
    "        turbine = turbine_from_capacity(capacity)\n",
    "\n",
    "        # location parameters\n",
    "        lat = df_offshore_wind['lat'][i]\n",
    "        lon = df_offshore_wind['lon'][i]\n",
    "\n",
    "        print(lat, lon, date_from, date_to, capacity, height, turbine)\n",
    "\n",
    "        # request data from renewables ninja\n",
    "        wind = renewables_ninja_API.request_wind(\n",
    "            token, lat, lon, date_from, date_to,\n",
    "            capacity, height, turbine)\n",
    "\n",
    "        wind['data'] = wind['data'].rename(\n",
    "            columns={'electricity': df_offshore_wind['Site Name'][i]})\n",
    "        # multiply by number of wind turbines\n",
    "        wind['data'] = wind['data'] * df_offshore_wind['No. of Turbines'][i]\n",
    "        wind['normalised'] = wind['data'] / (capacity * df_offshore_wind['No. of Turbines'][i])\n",
    "        output_series.append(wind['data'])\n",
    "        output_series_normalised.append(wind['normalised'])\n",
    "        output_series_metadata[df_offshore_wind['Site Name'][i]] = wind['metadata']\n",
    "\n",
    "        # gathers all the time series into one dataframe\n",
    "        df_out = pd.concat(output_series, axis=1)\n",
    "        df_out_norm = pd.concat(output_series_normalised, axis=1)\n",
    "\n",
    "        # want to save these into pickle files\n",
    "        df_out.to_pickle(\"data/renewables/\" + str(year) + \"/offshore_time_series.pkl\")\n",
    "        df_out_norm.to_pickle(\"data/renewables/\" + str(year) + \"/offshore_time_series_norm.pkl\")\n",
    "        with open('data/renewables/' + str(year) + '/offshore_metadata.pkl', 'wb') as handle:\n",
    "            pickle.dump(\n",
    "                output_series_metadata, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa22acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onshore_wind_time_series(df, year, date_from, date_to):\n",
    "    \"\"\"onshore wind time series download from renewables ninja\n",
    "\n",
    "    writes the timeseries to pickle file in relevant folder\n",
    "    note that only single year can be accessed\n",
    "\n",
    "   Parameters\n",
    "    ----------\n",
    "    df : dataframe\n",
    "        REPD data, should use date corrected version\n",
    "    year: int/str\n",
    "        Year of simulation\n",
    "    date_from: str\n",
    "        time series date from\n",
    "    date_to: str\n",
    "        time series date to\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "\n",
    "    # aim is to extract power series for\n",
    "    # offshore wind farms from renewables.ninja\n",
    "    df_onshore_wind = df.loc[df['Technology Type'] == 'Wind Onshore']\n",
    "    df_onshore_wind = df_onshore_wind.reset_index()\n",
    "\n",
    "    # check that data is available\n",
    "    if df_onshore_wind['No. of Turbines'].isnull().values.any() == True:\n",
    "        raise Exception(\"Number of turbines values must be provided, please fill in missing data in csv file\")\n",
    "    if df_onshore_wind['Turbine Capacity (MW)'].isnull().values.any() == True:\n",
    "        raise Exception(\"Number of turbines values must be provided, please fill in missing data in csv file\")\n",
    "\n",
    "    output_series = []\n",
    "    output_series_normalised = []\n",
    "    output_series_metadata = {}\n",
    "\n",
    "    length = df_onshore_wind.index\n",
    "    # length = range(3)\n",
    "    print(length, ' number of requests.')\n",
    "    for i in range(len(length)):\n",
    "\n",
    "        print(i)\n",
    "        print(df_onshore_wind['Site Name'][i])\n",
    "\n",
    "        # multiplied by 1000 to convert to kW\n",
    "        capacity = df_onshore_wind['Turbine Capacity (MW)'][i] * 1000\n",
    "\n",
    "        # check if height given\n",
    "        if df_onshore_wind['Height of Turbines (m)'][i] == 'NaN':\n",
    "            height = df_onshore_wind['Height of Turbines (m)'][i]\n",
    "        else:\n",
    "            # need to estimate height from turbine capacity using regression\n",
    "            height = wind_hub_height_to_capacity_regression(\n",
    "                capacity)\n",
    "\n",
    "        # height is limited to 150m\n",
    "        height = min(height, 150)\n",
    "\n",
    "        # need to figure out which turbine to use for power curve\n",
    "        # vestas has a wide range, let just use their ones\n",
    "        turbine = turbine_from_capacity(capacity)\n",
    "\n",
    "        # location parameters\n",
    "        lat = df_onshore_wind['lat'][i]\n",
    "        lon = df_onshore_wind['lon'][i]\n",
    "\n",
    "        print(lat, lon, date_from, date_to, capacity, height, turbine)\n",
    "\n",
    "        # request data from renewables ninja\n",
    "        wind = renewables_ninja_API.request_wind(\n",
    "            token, lat, lon, date_from, date_to,\n",
    "            capacity, height, turbine)\n",
    "\n",
    "        wind['data'] = wind['data'].rename(\n",
    "            columns={'electricity': df_onshore_wind['Site Name'][i]})\n",
    "        # multiply by number of wind turbines\n",
    "        wind['data'] = wind['data'] * df_onshore_wind['No. of Turbines'][i]\n",
    "        wind['normalised'] = wind['data'] / (capacity * df_onshore_wind['No. of Turbines'][i])\n",
    "        output_series.append(wind['data'])\n",
    "        output_series_normalised.append(wind['normalised'])\n",
    "        output_series_metadata[df_onshore_wind['Site Name'][i]] = wind['metadata']\n",
    "\n",
    "        # save for each timestep due to loss of connection and other errors\n",
    "\n",
    "        # gathers all the time series into one dataframe\n",
    "        df_out = pd.concat(output_series, axis=1)\n",
    "        df_out_norm = pd.concat(output_series_normalised, axis=1)\n",
    "\n",
    "        # want to save these into pickle files\n",
    "        df_out.to_pickle(\"data/renewables/\" + str(year) + \"/onshore_time_series.pkl\")\n",
    "        df_out_norm.to_pickle(\"data/renewables/\" + str(year) + \"/onshore_time_series_norm.pkl\")\n",
    "        with open('data/renewables/' + str(year) + '/onshore_metadata.pkl', 'wb') as handle:\n",
    "            pickle.dump(\n",
    "                output_series_metadata, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe55acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PV_time_series(df, year, date_from, date_to):\n",
    "    \"\"\"PV time series download from renewables ninja\n",
    "\n",
    "    writes the timeseries to pickle file in relevant folder\n",
    "    note that only single year can be accessed\n",
    "\n",
    "   Parameters\n",
    "    ----------\n",
    "    df : dataframe\n",
    "        REPD data, should use date corrected version\n",
    "    year: int/str\n",
    "        Year of simulation\n",
    "    date_from: str\n",
    "        time series date from\n",
    "    date_to: str\n",
    "        time series date to\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    # aim is to extract power series for\n",
    "    # PV from renewables.ninja\n",
    "    df_PV = df.loc[df['Technology Type'] == 'Solar Photovoltaics']\n",
    "    df_PV = df_PV.reset_index()\n",
    "\n",
    "    output_series = []\n",
    "    output_series_normalised = []\n",
    "    output_series_metadata = {}\n",
    "\n",
    "    length = df_PV.index\n",
    "    # length = range(3)\n",
    "    print(length)\n",
    "    for i in range(len(length)):\n",
    "\n",
    "        print(i)\n",
    "        print(df_PV['Site Name'][i])\n",
    "\n",
    "        # multiplied by 1000 to convert to kW\n",
    "        capacity = df_PV['Installed Capacity (MWelec)'][i] * 1000\n",
    "        system_loss = 0.1\n",
    "        tracking = 0\n",
    "        tilt = 35\n",
    "        azim = 180\n",
    "\n",
    "        # location parameters\n",
    "        lat = df_PV['lat'][i]\n",
    "        lon = df_PV['lon'][i]\n",
    "\n",
    "        print(lat, lon, date_from, date_to, capacity,\n",
    "              system_loss, tracking, tilt, azim)\n",
    "\n",
    "        # request data from renewables ninja\n",
    "        PV = renewables_ninja_API.request_PV(\n",
    "            token, lat, lon, date_from, date_to, capacity,\n",
    "            system_loss, tracking, tilt, azim)\n",
    "\n",
    "        PV['data'] = PV['data'].rename(\n",
    "            columns={'electricity': df_PV['Site Name'][i]})\n",
    "        PV['normalised'] = PV['data'] / capacity\n",
    "        output_series.append(PV['data'])\n",
    "        output_series_normalised.append(PV['normalised'])\n",
    "        output_series_metadata[df_PV['Site Name'][i]] = PV['metadata']\n",
    "\n",
    "        # save for each timestep due to loss of connection and other errors\n",
    "\n",
    "        # gathers all the time series into one dataframe\n",
    "        df_out = pd.concat(output_series, axis=1)\n",
    "        df_out_norm = pd.concat(output_series_normalised, axis=1)\n",
    "\n",
    "        # want to save these into pickle files\n",
    "        df_out.to_pickle('data/renewables/' + str(year) + '/PV_time_series.pkl')\n",
    "        df_out_norm.to_pickle('data/renewables/' + str(year) + '/PV_time_series_norm.pkl')\n",
    "        with open('data/renewables/' + str(year) + '/PV_metadata.pkl', 'wb') as handle:\n",
    "            pickle.dump(\n",
    "                output_series_metadata, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14813b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wind_hub_height_to_capacity_regression(capacity):\n",
    "    \"\"\"guesses hub height from capacity\n",
    "\n",
    "   Parameters\n",
    "    ----------\n",
    "    capacity : int/float\n",
    "        capacity of wind turbine\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    hub_height : int\n",
    "        predicted hub height of wind turbine\n",
    "    \"\"\"\n",
    "    file = 'data/renewables/wind_regression.csv'\n",
    "    df = pd.read_csv(file)\n",
    "    # values converts it into a numpy array\n",
    "    X = df['Rated Capacity'].values.reshape(-1, 1)\n",
    "    # -1 means that calculate the dimension of rows, but have 1 column\n",
    "    Y = df['Hub Height'].values.reshape(-1, 1)\n",
    "    linear_regressor = LinearRegression()  # create object for the class\n",
    "    linear_regressor.fit(X, Y)  # perform linear regression\n",
    "\n",
    "    # get value and reshape into single value and convert to int\n",
    "    return int(linear_regressor.predict([[capacity]])[:, 0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68f8772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turbine_from_capacity(capacity):\n",
    "    \"\"\"guesses turbine type from capacity using closest capacity in list\n",
    "\n",
    "   Parameters\n",
    "    ----------\n",
    "    capacity : int/float\n",
    "        capacity of wind turbine\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    turbine : str\n",
    "        predicted turbine type\n",
    "    \"\"\"\n",
    "    turbine_data = {225: 'Vestas V29 225',\n",
    "                    500: 'Vestas V39 500',\n",
    "                    600: 'Vestas V44 600',\n",
    "                    660: 'Vestas V47 660',\n",
    "                    850: 'Vestas V52 850',\n",
    "                    1000: 'NEG Micon NM60 1000',\n",
    "                    1650: 'Vestas V66 1650',\n",
    "                    1750: 'Vestas V66 1750',\n",
    "                    1800: 'Vestas V80 1800',\n",
    "                    2000: 'Vestas V90 2000',\n",
    "                    3000: 'Vestas V90 3000',\n",
    "                    3300: 'Vestas V112 3300',\n",
    "                    # 3400: 'REpower 3 4M',\n",
    "                    5000: 'REpower 5M',\n",
    "                    6000: 'REpower 6M'}\n",
    "\n",
    "    turbine = turbine_data.get(capacity) or turbine_data[\n",
    "        min(turbine_data.keys(),\n",
    "            key=lambda key: abs(key - capacity))]\n",
    "    # turbine = turbine.replace(\".\", \" \")\n",
    "    return turbine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b46e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wind_onshore_corrected(year):\n",
    "    \"\"\"corrects wind onshore normalised using historical annual generation data\n",
    "\n",
    "   Parameters\n",
    "    ----------\n",
    "    year : int/float/str\n",
    "        year of time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        timeseries dataframe with corrected factor included\n",
    "    \"\"\"\n",
    "\n",
    "    file = \"data/renewables/\" + str(year) + \"/onshore_time_series.pkl\"\n",
    "    df_onshore = renewables.fix_timeseries_res_for_year(file, year, 'Wind Onshore')\n",
    "    # print(df_onshore)\n",
    "    # print(df_onshore.columns)\n",
    "    # total = df_onshore.to_numpy().sum() / 1000000000\n",
    "    # print(total, 'TWh')\n",
    "\n",
    "    # data from https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/875384/Wind_powered_electricity_in_the_UK.pdf\n",
    "    # reported generation data for onshore wind in UK\n",
    "    gen_data = {'2010': 7.226,\n",
    "                '2011': 10.814,\n",
    "                '2012': 12.244,\n",
    "                '2013': 16.925,\n",
    "                '2014': 18.555,\n",
    "                '2015': 22.852,\n",
    "                '2016': 20.749,\n",
    "                '2017': 28.717,\n",
    "                '2018': 30.217,\n",
    "                '2019': 32.205,\n",
    "                '2020': 35.}  # 2020 assumed not from data\n",
    "    gen_year = gen_data[str(year)]\n",
    "\n",
    "    # then need to adjust the normalised time series\n",
    "    factor = gen_year / (df_onshore.to_numpy().sum() / 1000000000)\n",
    "    file = \"data/renewables/\" + str(year) + \"/onshore_time_series_norm.pkl\"\n",
    "    df_onshore_norm = renewables.fix_timeseries_res_for_year(file, year, 'Wind Onshore')\n",
    "\n",
    "    # df2 = df_onshore * factor\n",
    "    # total = df2.to_numpy().sum() / 1000000000\n",
    "    # print(total, 'TWh')\n",
    "\n",
    "    df_onshore_corrected = df_onshore_norm * factor\n",
    "    # print(df_onshore_corrected)\n",
    "\n",
    "    return df_onshore_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a21e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wind_onshore_corrected_series(year):\n",
    "    \"\"\"corrects wind onshore series using historical annual generation data\n",
    "\n",
    "   Parameters\n",
    "    ----------\n",
    "    year : int/float/str\n",
    "        year of time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        timeseries dataframe with corrected factor included\n",
    "    \"\"\"\n",
    "    file = \"data/renewables/\" + str(year) + \"/onshore_time_series.pkl\"\n",
    "    df_onshore = renewables.fix_timeseries_res_for_year(file, year, 'Wind Onshore')\n",
    "    # print(df_onshore)\n",
    "    # print(df_onshore.columns)\n",
    "    # total = df_onshore.to_numpy().sum() / 1000000000\n",
    "    # print(total, 'TWh')\n",
    "\n",
    "    # data from https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/875384/Wind_powered_electricity_in_the_UK.pdf\n",
    "    # reported generation data for onshore wind in UK\n",
    "    gen_data = {'2010': 7.226,\n",
    "                '2011': 10.814,\n",
    "                '2012': 12.244,\n",
    "                '2013': 16.925,\n",
    "                '2014': 18.555,\n",
    "                '2015': 22.852,\n",
    "                '2016': 20.749,\n",
    "                '2017': 28.717,\n",
    "                '2018': 30.217,\n",
    "                '2019': 32.205,\n",
    "                '2020': 35.}  # 2020 assumed not from data\n",
    "    gen_year = gen_data[str(year)]\n",
    "\n",
    "    # then need to adjust the normalised time series\n",
    "    factor = gen_year / (df_onshore.to_numpy().sum() / 1000000000)\n",
    "    file = \"data/renewables/\" + str(year) + \"/onshore_time_series_norm.pkl\"\n",
    "    # df_onshore_norm = renewables.fix_timeseries_res_for_year(file, year, 'Wind Onshore')\n",
    "\n",
    "    df2 = df_onshore * factor\n",
    "\n",
    "    # total = df2.to_numpy().sum() / 1000000000\n",
    "    # print(total, 'TWh')\n",
    "\n",
    "    # df_onshore_corrected = df_onshore_norm * factor\n",
    "    # print(df_onshore_corrected)\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea04ba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wind_offshore_corrected(year):\n",
    "    \"\"\"corrects wind offshore normalised using historical annual generation data\n",
    "\n",
    "   Parameters\n",
    "    ----------\n",
    "    year : int/float/str\n",
    "        year of time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        timeseries dataframe with corrected factor included\n",
    "    \"\"\"\n",
    "    file = \"data/renewables/\" + str(year) + \"/offshore_time_series.pkl\"\n",
    "    df_offshore = renewables.fix_timeseries_res_for_year(file, year, 'Wind Offshore')\n",
    "    # print(df_offshore.to_numpy().sum() / 1000000000, 'TWh')\n",
    "    # print(df_onshore)\n",
    "    # print(df_onshore.columns)\n",
    "    # total = df_onshore.to_numpy().sum() / 1000000000\n",
    "    # print(total, 'TWh')\n",
    "\n",
    "    # data from https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/875384/Wind_powered_electricity_in_the_UK.pdf\n",
    "    # reported generation data for onshore wind in UK\n",
    "    gen_data = {'2010': 3.060,\n",
    "                '2011': 5.149,\n",
    "                '2012': 7.603,\n",
    "                '2013': 11.472,\n",
    "                '2014': 13.405,\n",
    "                '2015': 17.423,\n",
    "                '2016': 16.406,\n",
    "                '2017': 20.916,\n",
    "                '2018': 26.687,\n",
    "                '2019': 31.929,\n",
    "                '2020': 38.}  # 2020 assumed not from data\n",
    "    gen_year = gen_data[str(year)]\n",
    "\n",
    "    # then need to adjust the normalised time series\n",
    "    factor = gen_year / (df_offshore.to_numpy().sum() / 1000000000)\n",
    "    file = \"data/renewables/\" + str(year) + \"/offshore_time_series_norm.pkl\"\n",
    "    df_offshore_norm = renewables.fix_timeseries_res_for_year(file, year, 'Wind Offshore')\n",
    "\n",
    "    # df2 = df_offshore * factor\n",
    "    # total = df2.to_numpy().sum() / 1000000000\n",
    "    # print(total, 'TWh')\n",
    "\n",
    "    df_offshore_corrected = df_offshore_norm * factor\n",
    "    # total = df_offshore_corrected.to_numpy().sum() / 1000000000\n",
    "    # print(total, 'TWh')\n",
    "    # print(df_offshore_corrected)\n",
    "\n",
    "    return df_offshore_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d9df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wind_offshore_corrected_series(year):\n",
    "    \"\"\"corrects wind offshore series using historical annual generation data\n",
    "\n",
    "   Parameters\n",
    "    ----------\n",
    "    year : int/float/str\n",
    "        year of time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        timeseries dataframe with corrected factor included\n",
    "    \"\"\"\n",
    "    file = \"data/renewables/\" + str(year) + \"/offshore_time_series.pkl\"\n",
    "    df_offshore = renewables.fix_timeseries_res_for_year(file, year, 'Wind Offshore')\n",
    "    # print(df_offshore.to_numpy().sum() / 1000000000, 'TWh')\n",
    "    # print(df_onshore)\n",
    "    # print(df_onshore.columns)\n",
    "    # total = df_onshore.to_numpy().sum() / 1000000000\n",
    "    # print(total, 'TWh')\n",
    "\n",
    "    # data from https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/875384/Wind_powered_electricity_in_the_UK.pdf\n",
    "    # reported generation data for onshore wind in UK\n",
    "    gen_data = {'2010': 3.060,\n",
    "                '2011': 5.149,\n",
    "                '2012': 7.603,\n",
    "                '2013': 11.472,\n",
    "                '2014': 13.405,\n",
    "                '2015': 17.423,\n",
    "                '2016': 16.406,\n",
    "                '2017': 20.916,\n",
    "                '2018': 26.687,\n",
    "                '2019': 31.929,\n",
    "                '2020': 38.}  # 2020 assumed not from data\n",
    "    gen_year = gen_data[str(year)]\n",
    "\n",
    "    # then need to adjust the normalised time series\n",
    "    factor = gen_year / (df_offshore.to_numpy().sum() / 1000000000)\n",
    "    file = \"data/renewables/\" + str(year) + \"/offshore_time_series_norm.pkl\"\n",
    "    # df_offshore_norm = data_reader_writer.fix_timeseries_res_for_year(file, year, 'Wind Offshore')\n",
    "\n",
    "    df2 = df_offshore * factor\n",
    "    # total = df2.to_numpy().sum() / 1000000000\n",
    "    # print(total, 'TWh')\n",
    "\n",
    "    # df_offshore_corrected = df_offshore_norm * factor\n",
    "    # total = df_offshore_corrected.to_numpy().sum() / 1000000000\n",
    "    # print(total, 'TWh')\n",
    "    # print(df_offshore_corrected)\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8adabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PV_corrected(year):\n",
    "    \"\"\"corrects PV normalised using historical annual generation data\n",
    "\n",
    "   Parameters\n",
    "    ----------\n",
    "    year : int/float/str\n",
    "        year of time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        timeseries dataframe with corrected factor included\n",
    "    \"\"\"\n",
    "    file = \"data/renewables/\" + str(year) + \"/PV_time_series.pkl\"\n",
    "    df_PV = renewables.fix_timeseries_res_for_year(file, year, 'Solar Photovoltaics')\n",
    "    # print(df_PV.to_numpy().sum() / 1000000000, 'TWh')\n",
    "    # print(df_PV)\n",
    "    # print(df_PV.columns)\n",
    "    # total = df_PV.to_numpy().sum() / 1000000000\n",
    "    # print(total, 'TWh')\n",
    "\n",
    "    # data from https://en.wikipedia.org/wiki/Solar_power_in_the_United_Kingdom\n",
    "    # reported generation data for PV in UK\n",
    "    gen_data = {'2010': 0.033,\n",
    "                '2011': 0.259,\n",
    "                '2012': 1.328,\n",
    "                '2013': 2.015,\n",
    "                '2014': 4.050,\n",
    "                '2015': 7.561,\n",
    "                '2016': 10.292,\n",
    "                '2017': 11.525,\n",
    "                '2018': 12.922,\n",
    "                '2019': 13.616,\n",
    "                '2020': 14.3}  # 2020 assumed, not from data\n",
    "    gen_year = gen_data[str(year)]\n",
    "\n",
    "    # then need to adjust the normalised time series\n",
    "    factor = gen_year / (df_PV.to_numpy().sum() / 1000000000)\n",
    "    file = \"data/renewables/\" + str(year) + \"/PV_time_series_norm.pkl\"\n",
    "    df_PV_norm = renewables.fix_timeseries_res_for_year(file, year, 'Solar Photovoltaics')\n",
    "\n",
    "    # df2 = df_PV * factor\n",
    "    # total = df2.to_numpy().sum() / 1000000000\n",
    "    # print(total, 'TWh')\n",
    "\n",
    "    df_PV_corrected = df_PV_norm * factor\n",
    "    # total = df_PV_corrected.to_numpy().sum() / 1000000000\n",
    "\n",
    "    return df_PV_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33362d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PV_corrected_series(year):\n",
    "    \"\"\"corrects PV series using historical annual generation data\n",
    "\n",
    "   Parameters\n",
    "    ----------\n",
    "    year : int/float/str\n",
    "        year of time series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        timeseries dataframe with corrected factor included\n",
    "    \"\"\"\n",
    "\n",
    "    file = \"data/renewables/\" + str(year) + \"/PV_time_series.pkl\"\n",
    "    df_PV = renewables.fix_timeseries_res_for_year(file, year, 'Solar Photovoltaics')\n",
    "    # print(df_PV.to_numpy().sum() / 1000000000, 'TWh')\n",
    "    # print(df_PV)\n",
    "    # print(df_PV.columns)\n",
    "    # total = df_PV.to_numpy().sum() / 1000000000\n",
    "    # print(total, 'TWh')\n",
    "\n",
    "    # data from https://en.wikipedia.org/wiki/Solar_power_in_the_United_Kingdom\n",
    "    # reported generation data for PV in UK\n",
    "    gen_data = {'2010': 0.033,\n",
    "                '2011': 0.259,\n",
    "                '2012': 1.328,\n",
    "                '2013': 2.015,\n",
    "                '2014': 4.050,\n",
    "                '2015': 7.561,\n",
    "                '2016': 10.292,\n",
    "                '2017': 11.525,\n",
    "                '2018': 12.922,\n",
    "                '2019': 13.616,\n",
    "                '2020': 14.3}  # 2020 assumed, not from data\n",
    "    gen_year = gen_data[str(year)]\n",
    "\n",
    "    # then need to adjust the normalised time series\n",
    "    factor = gen_year / (df_PV.to_numpy().sum() / 1000000000)\n",
    "    file = \"data/renewables/\" + str(year) + \"/PV_time_series_norm.pkl\"\n",
    "    # df_PV_norm = data_reader_writer.fix_timeseries_res_for_year(file, year, 'Solar Photovoltaics')\n",
    "\n",
    "    df2 = df_PV * factor\n",
    "    # total = df2.to_numpy().sum() / 1000000000\n",
    "    # print(total, 'TWh')\n",
    "\n",
    "    # df_PV_corrected = df_PV_norm * factor\n",
    "    # total = df_PV_corrected.to_numpy().sum() / 1000000000\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61550e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    year = 2011\n",
    "    # read in the renewables dataframe\n",
    "    df = renewables.REPD_date_corrected(year)\n",
    "    # df_pv = df.loc[df['Technology Type'] == 'Solar Photovoltaics'].reset_index(drop=True)\n",
    "    # print(df_pv)\n",
    "\n",
    "    # token for renewables.ninja API\n",
    "\n",
    "    # insert your own here\n",
    "    token = 'INSERT_OWN_API_TOKEN'\n",
    "\n",
    "    # dates required\n",
    "    date_from = '2011-01-01'\n",
    "    date_to = '2011-12-31'\n",
    "\n",
    "    # fix_PV()\n",
    "\n",
    "    offshore_wind_time_series(df, year, date_from, date_to)\n",
    "    onshore_wind_time_series(df, year, date_from, date_to)\n",
    "    PV_time_series(df, year, date_from, date_to)\n",
    "\n",
    "    # wind_onshore_corrected(year)\n",
    "    # wind_offshore_corrected(year)\n",
    "    # PV_corrected(year)\n",
    "\n",
    "    # df = pickle.load(open(\"data/renewables/PV_time_series.pkl\", \"rb\"))\n",
    "    # print(df.head(24))\n",
    "    # df2 = pickle.load(open(\"data/renewables/PV_time_series_norm.pkl\", \"rb\"))\n",
    "    # print(df2.head(24))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

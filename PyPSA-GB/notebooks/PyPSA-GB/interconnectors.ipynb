{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809ff344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4985c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.cleaning import unify_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a8316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_interconnectors():\n",
    "    \"\"\"reads the interconnector import/export data from ESPENI database\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        ESPENI interconnector data, see dates below\n",
    "    \"\"\"\n",
    "\n",
    "    # using espeni data set\n",
    "    file = '../data/demand/espeni.csv'\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    dti = pd.date_range(\n",
    "        start='2008-11-05 22:00:00', end='2021-06-06 23:30:00', freq='0.5h')\n",
    "    df = df.set_index(dti)\n",
    "    \n",
    "    df = df[['POWER_NGEM_BRITNED_FLOW_MW', 'POWER_NGEM_EAST_WEST_FLOW_MW',\n",
    "             'POWER_NGEM_MOYLE_FLOW_MW', 'POWER_NGEM_NEMO_FLOW_MW',\n",
    "             'POWER_NGEM_IFA_FLOW_MW', 'POWER_NGEM_IFA2_FLOW_MW']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4993d285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_interconnectors(start, end, freq):\n",
    "\n",
    "    # add lines which are used to handle flows of interconnectors\n",
    "    df_IC = pd.read_csv('../data/interconnectors/links.csv', index_col=0)\n",
    "    df_lines = pd.read_csv('LOPF_data/lines.csv', index_col=0)\n",
    "    df_IC2 = df_IC.copy()\n",
    "    df_IC2['r'] = 0.0\n",
    "    df_IC2['x'] = 0.0001\n",
    "    df_IC2['b'] = 0.0\n",
    "    df_IC2['s_nom'] = df_IC2.loc[:, 'p_nom']\n",
    "    df_IC2.drop(columns=['p_nom', 'carrier'], inplace=True)\n",
    "    df_IC2 = df_IC2.reset_index(drop=True)\n",
    "\n",
    "    # append interconnectors as lines\n",
    "    df_lines = pd.concat([df_lines, df_IC2], ignore_index=True, sort=False)\n",
    "\n",
    "    df_lines.to_csv('LOPF_data/lines.csv', header=True)\n",
    "\n",
    "    # check if links.csv file exists, if it does then delete it\n",
    "    filePath = 'LOPF_data/links.csv'\n",
    "    if os.path.exists(filePath):\n",
    "        os.remove(filePath)\n",
    "    # check if links.csv file exists, if it does then delete it\n",
    "    filePath = 'UC_data/links.csv'\n",
    "    if os.path.exists(filePath):\n",
    "        os.remove(filePath)\n",
    "\n",
    "    # going to add interconnectors as import -> gen, export -> load\n",
    "    # first add the interconnectors as named loads\n",
    "    df_load = pd.read_csv('UC_data/loads.csv')\n",
    "    name_dic = {'name': ['BritNed', 'EastWest', 'Moyle',\n",
    "                         'Nemo', 'IFA', 'IFA2'],\n",
    "                'bus': 'bus'}\n",
    "    IC_load = pd.DataFrame(name_dic)\n",
    "    df_load = pd.concat([df_load, IC_load], ignore_index=True)\n",
    "\n",
    "    df_load.to_csv('UC_data/loads.csv', index=False, header=True)\n",
    "\n",
    "    # then add the interconnectors as named generators with basic attributes\n",
    "    df_gen = pd.read_csv('UC_data/generators.csv', index_col=0)\n",
    "    # use hydro row as a template\n",
    "    IC_gen = df_gen.iloc[[0]]\n",
    "    result = df_gen\n",
    "    for i in name_dic['name']:\n",
    "        IC_gen.index = [i]\n",
    "        IC_gen['carrier'] = 'Interconnector'\n",
    "        IC_gen['type'] = 'Interconnector'\n",
    "        IC_gen['p_nom'] = df_IC['p_nom'][i]\n",
    "        IC_gen['marginal_cost'] = 20\n",
    "        IC_gen['committable'] = False\n",
    "        IC_gen['min_up_time'] = 0\n",
    "        IC_gen['min_down_time'] = 0\n",
    "        IC_gen['ramp_limit_up'] = 1\n",
    "        IC_gen['ramp_limit_down'] = 1\n",
    "        IC_gen['p_min_pu'] = 0\n",
    "        IC_gen['up_time_before'] = 0\n",
    "        IC_gen['start_up_cost'] = 0\n",
    "\n",
    "        result = pd.concat([result, IC_gen])\n",
    "\n",
    "    # write the appended csv file\n",
    "    result.index.name = 'name'\n",
    "    result.to_csv('UC_data/generators.csv', header=True)\n",
    "\n",
    "    # for LOPF need to also provide bus\n",
    "    IC_names_buses = dict(zip(df_IC.index, df_IC['bus1'].values))\n",
    "    df_gen2 = pd.read_csv('LOPF_data/generators.csv', index_col=0)\n",
    "    # use row zero as a template\n",
    "    IC_gen2 = df_gen2.iloc[[0]]\n",
    "    df_gen2 = pd.read_csv('LOPF_data/generators.csv', index_col=0)\n",
    "    result2 = df_gen2\n",
    "    for i in name_dic['name']:\n",
    "        IC_gen2.index = [i]\n",
    "        IC_gen2['carrier'] = 'Interconnector'\n",
    "        IC_gen2['type'] = 'Interconnector'\n",
    "        IC_gen2['p_nom'] = df_IC['p_nom'][i]\n",
    "        IC_gen2['bus'] = IC_names_buses[i]\n",
    "        IC_gen2['marginal_cost'] = 20\n",
    "\n",
    "        result2 = pd.concat([result2, IC_gen2])\n",
    "\n",
    "    # write the appended csv file\n",
    "    result2.index.name = 'name'\n",
    "    result2.to_csv('LOPF_data/generators.csv', header=True)\n",
    "\n",
    "    # now add the flows as fixed generators and loads\n",
    "    df_gen_series = pd.read_csv('UC_data/generators-p_max_pu.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "    df = read_interconnectors()\n",
    "    df = df.loc[start:end]\n",
    "    df.rename(columns={'POWER_NGEM_BRITNED_FLOW_MW': 'BritNed',\n",
    "                       'POWER_NGEM_EAST_WEST_FLOW_MW': 'EastWest',\n",
    "                       'POWER_NGEM_MOYLE_FLOW_MW': 'Moyle',\n",
    "                       'POWER_NGEM_NEMO_FLOW_MW': 'Nemo',\n",
    "                       'POWER_NGEM_IFA_FLOW_MW': 'IFA',\n",
    "                       'POWER_NGEM_IFA2_FLOW_MW': 'IFA2'}, inplace=True)\n",
    "\n",
    "    df, df_gen_series = unify_index([df, df_gen_series], freq)\n",
    "    df.index = df_gen_series.index\n",
    "\n",
    "    # exports will be loads\n",
    "    df_IC_load = df.where(df < 0, 0) * -1\n",
    "\n",
    "    # set p_min_pu and p_max_pu to per unit of p_nom\n",
    "    for IC in range(len(df_IC.index)):\n",
    "        p_nom = df_IC.iloc[IC, 3]\n",
    "        df.iloc[:, IC] /= p_nom\n",
    "\n",
    "    # split the exports and imports\n",
    "    # where imports will be generators\n",
    "    df_IC_gen = df.where(df > 0, 0)\n",
    "\n",
    "    result = pd.concat([df_gen_series, df_IC_gen], axis=1)\n",
    "    # # fix the interconnector flows by setting max and min\n",
    "    df_IC_gen.to_csv('UC_data/generators-p_min_pu.csv', header=True)\n",
    "    result.to_csv('UC_data/generators-p_max_pu.csv', header=True)\n",
    "\n",
    "    # do similar for LOPF\n",
    "    df_gen_series2 = pd.read_csv(\n",
    "        'LOPF_data/generators-p_max_pu.csv', index_col=0, parse_dates=True)\n",
    "    result = pd.concat([df_gen_series2, df_IC_gen], axis=1)\n",
    "    df_IC_gen.to_csv('LOPF_data/generators-p_min_pu.csv', header=True)\n",
    "    result.to_csv('LOPF_data/generators-p_max_pu.csv', header=True)\n",
    "\n",
    "    # add the exports as loads\n",
    "    df_load_series = pd.read_csv('UC_data/loads-p_set.csv', index_col=0, parse_dates=True)\n",
    "    df_load_series, df = unify_index([df_load_series, df], freq)\n",
    "    df_load_series.index = df.index\n",
    "\n",
    "    result1 = pd.concat([df_load_series, df_IC_load], axis=1)\n",
    "\n",
    "    result1.to_csv('UC_data/loads-p_set.csv', header=True)\n",
    "\n",
    "    # do similar for LOPF\n",
    "    df_load_series2 = pd.read_csv('LOPF_data/loads-p_set.csv', index_col=0, parse_dates=True)\n",
    "    df_load_series2, df = unify_index([df_load_series2, df], freq)\n",
    "    df_load_series2.index = df.index\n",
    "    df_IC_load.rename(\n",
    "        columns={'BritNed': 'Netherlands', 'EastWest': 'Ireland',\n",
    "                 'Moyle': 'N. Ireland', 'Nemo': 'Belgium',\n",
    "                 'IFA': 'France1', 'IFA2': 'France2'}, inplace=True)\n",
    "\n",
    "    result1 = pd.concat([df_load_series2, df_IC_load], axis=1)\n",
    "\n",
    "    result1.to_csv('LOPF_data/loads-p_set.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459a2ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def future_interconnectors(year, scenario, FES):\n",
    "\n",
    "    # what interconnectors in future\n",
    "    # read in future interconnector csv data\n",
    "    # https://www.ofgem.gov.uk/energy-policy-and-regulation/policy-and-regulatory-programmes/interconnectors\n",
    "    df_IC_future = pd.read_csv('../data/interconnectors/links_future.csv', index_col=0)\n",
    "    df_IC_future['p_min_pu'] = -1\n",
    "    # filter by date\n",
    "    df = df_IC_future.reset_index().set_index(['installed date'])\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    to_date = str(year) + '-01-01'\n",
    "    filtered_df = df.loc[:to_date]\n",
    "    df_IC = filtered_df.set_index(['name'])\n",
    "    # only scaling if year > 2025\n",
    "    if year > 2025:\n",
    "        # what is the 2025 capacity\n",
    "        IC_2025_cap = df_IC['p_nom'].sum() / 1000\n",
    "        # need to scale the interconnectors for beyond 2025 using FES data\n",
    "        # read in the FES data\n",
    "        if FES == 2021:\n",
    "            df_FES = pd.read_excel(\n",
    "                '../data/FES2021/FES 2021 Data Workbook V04.xlsx',\n",
    "                sheet_name='ES1', header=9, index_col=1)\n",
    "        if FES == 2022:\n",
    "            df_FES = pd.read_excel(\n",
    "                '../data/FES2022/FES2022 Workbook V4.xlsx',\n",
    "                sheet_name='ES1', header=9, index_col=1)\n",
    "        df_FES.dropna(axis='rows', inplace=True)\n",
    "        df_FES = df_FES[df_FES.Type.str.contains('Interconnectors', case=False)]\n",
    "        df_FES = df_FES[~df_FES.Variable.str.contains(r'\\(TWh\\)')]\n",
    "        cols = [0, 1, 2, 3, 4]\n",
    "        df_FES.drop(df_FES.columns[cols], axis=1, inplace=True)\n",
    "        date = str(year) + '-01-01'\n",
    "        try:\n",
    "            IC_cap_FES = float(df_FES.loc[scenario, date]) / 1000.\n",
    "        except:\n",
    "            IC_cap_FES = float(df_FES.loc[scenario, year]) / 1000.\n",
    "\n",
    "        # then consider what scaling factor is required\n",
    "        scaling_factor = round(IC_cap_FES / IC_2025_cap, 2)\n",
    "        # print(scaling_factor, 'scaling factor for interconnectors')\n",
    "        # scale the p_noms of the RES generators\n",
    "        for g in df_IC.index:\n",
    "            df_IC.loc[g, 'p_nom'] *= scaling_factor\n",
    "            # gen_tech_UC.loc[g, 'p_nom'] *= scaling_factor\n",
    "\n",
    "    # save csv for LOPF problem, but not UC which does not include lines??\n",
    "    df_IC.to_csv('LOPF_data/links.csv', index=True, header=True)\n",
    "\n",
    "    # try links with UC, but probably need to change buses\n",
    "    df_IC_UC = df_IC.copy()\n",
    "    df_IC_UC['bus1'] = 'bus'\n",
    "    df_IC_UC.to_csv('UC_data/links.csv', index=True, header=True)\n",
    "\n",
    "    # want to ensure that buses.csv has new buses from new interconnectors\n",
    "    # get original bus file\n",
    "    df_buses = pd.read_csv('LOPF_data/buses.csv', index_col=0)\n",
    "    df_buses_DC = df_buses.loc[df_buses['carrier'] == 'DC']\n",
    "    # compare buses to those of interconnectors\n",
    "    difference = list(set(df_IC.bus0.values) - set(df_buses_DC.index.values))\n",
    "    # read in csv file with new bus details\n",
    "    df_buses_new = pd.read_csv('../data/interconnectors/links_new_buses.csv', index_col=0)\n",
    "    df_buses_new = df_buses_new.dropna(axis='columns')\n",
    "    df_buses_to_add = df_buses_new.loc[difference]\n",
    "    # add buses to original buses file\n",
    "    df_buses = pd.concat([df_buses, df_buses_to_add])\n",
    "\n",
    "    df_buses.to_csv('LOPF_data/buses.csv', index=True, header=True)\n",
    "\n",
    "    # want to ensure that buses.csv has new buses from new interconnectors\n",
    "    # get original bus file\n",
    "    df_buses = pd.read_csv('UC_data/buses.csv', index_col=0)\n",
    "    # compare buses to those of interconnectors\n",
    "    difference = list(set(df_IC.bus0.values) - set(df_buses.index.values))\n",
    "    # read in csv file with new bus details\n",
    "    df_buses_new = pd.read_csv('../data/interconnectors/links_new_buses.csv', index_col=0)\n",
    "    df_buses_new = df_buses_new.dropna(axis='columns')\n",
    "    df_buses_to_add = df_buses_new.loc[difference]\n",
    "    # add buses to original buses file\n",
    "    df_buses = pd.concat([df_buses, df_buses_to_add])\n",
    "\n",
    "    df_buses.to_csv('UC_data/buses.csv', index=True, header=True)\n",
    "\n",
    "    # check if generators-p_min_pu exists and delete if so\n",
    "    # used in historical simulations but not wanted in future sims\n",
    "    try:\n",
    "        file = 'LOPF_data/generators-p_min_pu.csv'\n",
    "        os.remove(file)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        file = 'UC_data/generators-p_min_pu.csv'\n",
    "        os.remove(file)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6f425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    year = 2050\n",
    "    future_interconnectors(year)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

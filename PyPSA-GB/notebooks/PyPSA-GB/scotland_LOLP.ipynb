{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e631603f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pypsa\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.style.use('ggplot')\n",
    "import matplotlib.ticker as ticker \n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "import data_reader_writer\n",
    "import scotland_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d140d650",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "plt.style.use('plot_style.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d46fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rate(row, name_list, carrier, conversion_dict, power_stations, breakdown_rate, breakdowwn_rate_battery=None, storage_units= None):\n",
    "    for i in range(len(carrier)):\n",
    "        # if row[i] != [0]: only running stations\n",
    "        name = name_list[i]\n",
    "        fuel_type = convert_type(name, carrier, conversion_dict, power_stations)\n",
    "        if fuel_type != 'Battery':\n",
    "            rate = breakdown_rate[fuel_type]\n",
    "        else:\n",
    "            max_hours = storage_units[storage_units.index == name]['max_hours'].tolist()[0]\n",
    "            max_hours = np.rint(max_hours * 2) / 2\n",
    "            max_hours = min(max_hours, 4)\n",
    "            rate = breakdowwn_rate_battery[str(max_hours) + 'h']        \n",
    "        row[i] = rate\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a9fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_type(name, carrier, conversion_dict, power_stations):\n",
    "    type0 = carrier[name]\n",
    "    try:\n",
    "        type1 = conversion_dict[type0]\n",
    "    except:\n",
    "        if type0 == 'Natural Gas':\n",
    "            type1 = power_stations[power_stations['Station Name']==name]['Technology'].tolist()[0]\n",
    "        else:\n",
    "            type1 = 'Excluded'\n",
    "#             if 'new_type_list' not in globals():\n",
    "#                 global new_type_list\n",
    "#                 new_type_list = list()\n",
    "#             if type0 not in new_type_list:\n",
    "#                 new_type_list.append(type0)\n",
    "            print('Do not have break downrate for type ' + type0)\n",
    "    return type1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f97fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOLP(network, year, year_baseline=None, failures_type=None, failures_rate=None):\n",
    "    if year > 2020:\n",
    "        year = year_baseline\n",
    "    file = '../data/power stations/power_stations_locations_' + str(year) + '.csv'\n",
    "    power_stations = pd.read_csv(file, encoding='unicode_escape')\n",
    "    \n",
    "    bd_conversion_csv = pd.read_csv('../data/LOLE/bd_conversion_type.csv',index_col=0)\n",
    "    bd_conversion_dict = bd_conversion_csv.to_dict()['1']\n",
    "    \n",
    "    breakdown_rate = pd.read_csv('../data/LOLE/breakdown_rate.csv',index_col=0)\n",
    "    breakdowwn_rate_battery = pd.read_csv('../data/LOLE/breakdowwn_rate_battery.csv',index_col=0)\n",
    "    \n",
    "    if (failures_type is not None) and (failures_type is not None):\n",
    "        if type(failures_type) is not list:\n",
    "            failures_type= [failures_type]\n",
    "        if type(failures_rate) is not list:\n",
    "            failures_rate = [failures_rate]\n",
    "        if len(failures_type) != len(failures_rate):\n",
    "            failures_rate = failures_rate * len(failures_type)\n",
    "        for _ in range(len(failures_type)):\n",
    "            generator_type = failures_type[_]\n",
    "            if generator_type != 'Battery':\n",
    "                breakdown_rate.loc[generator_type] = 1 - (1 - breakdown_rate.loc[generator_type]) * failures_rate[_]\n",
    "            else:\n",
    "                breakdowwn_rate_battery['Breakdown Rate'] = 1 - (1-breakdowwn_rate_battery['Breakdown Rate']) * failures_rate[_]\n",
    "            \n",
    "    breakdown_rate = breakdown_rate.to_dict()['Breakdown Rate']\n",
    "    breakdowwn_rate_battery = breakdowwn_rate_battery.to_dict()['Breakdown Rate']\n",
    "    \n",
    "    generators_name_list = network.generators.index.tolist() ##\n",
    "    \n",
    "    #  generator units' breakdown rate time-series dataframe: generators_rate\n",
    "    generators_rate_col = generators_name_list\n",
    "    generators_rate_index = network.snapshots.copy()\n",
    "    generators_rate = pd.DataFrame(columns=generators_rate_col, index=generators_rate_index) \n",
    "    generators_rate.apply(lambda r: get_rate(r, generators_name_list, network.generators.carrier, bd_conversion_dict, power_stations, breakdown_rate), axis = 1)\n",
    "    \n",
    "    # storage units' breakdown rate time-series dataframe: storage_rate\n",
    "    storage_units_name_list = network.storage_units.index.tolist() \n",
    "    storage_units_rate_col = storage_units_name_list\n",
    "    storage_units_rate_index = network.snapshots.copy()\n",
    "    storage_units_rate = pd.DataFrame(columns=storage_units_rate_col, index=storage_units_rate_index) ##\n",
    "    storage_units_rate.apply(lambda r: get_rate(r, storage_units_name_list, network.storage_units.carrier, bd_conversion_dict, power_stations, breakdown_rate, breakdowwn_rate_battery, network.storage_units), axis = 1)\n",
    "    \n",
    "    # all units' breakdown rate\n",
    "    pd_rate = pd.concat([generators_rate, storage_units_rate], axis=1)\n",
    "    # pd_rate2 = pd_rate.copy()\n",
    "    \n",
    "    # caculate time series of weather dependent generators' outputs from input data \n",
    "\n",
    "    pd_stations = pd_rate.copy()\n",
    "    pd_stations_w = pd_stations[network.generators.index.tolist()][(pd_rate == 0)].dropna(axis=1,how='all').fillna(0)\n",
    "    pd_stations[network.generators.p_nom.index] = network.generators.p_nom.values\n",
    "    pd_stations[network.storage_units.p_nom.index] = network.storage_units.p_nom.values\n",
    "    pd_stations[pd_stations_w.columns] = network.generators_t.p_max_pu[pd_stations_w.columns] * network.generators.p_nom[pd_stations_w.columns]\n",
    "\n",
    "    pd_stations_all = pd_stations.copy()\n",
    "    \n",
    "    pd_stations_w = pd_stations[pd_stations_w.columns.tolist()]#[(pd_rate == 0)].dropna(axis=1,how='all').fillna(0)\n",
    "    ## Shoreline Wave, Tidal Barrage and Tidal Stream\n",
    "\n",
    "    pd_stations = pd_stations[(pd_rate < 1) & (pd_rate > 0)].dropna(axis=1,how='all').fillna(0)\n",
    "    \n",
    "    # Note: now, the time series of breakdown rate ONLY include non weather dependent units (i.e. convertional units)\n",
    "    pd_rate = pd_rate[pd_stations.columns]\n",
    "    \n",
    "    # net_demand\n",
    "    # calculate net_demand from input data (value is empty)\n",
    "    # net_demand = total demand - renewable (Weather Dependent) output.\n",
    "    net_demand = network.loads_t.p_set.sum(axis=1) - pd_stations_w.sum(axis=1)\n",
    "    \n",
    "    \n",
    "    # non renewable generator units' installed capacity\n",
    "    installed_capacity = pd.concat([network.generators.p_nom, network.storage_units.p_nom], axis=0)[pd_stations.columns].to_numpy()\n",
    "    \n",
    "    return installed_capacity, pd_rate.to_numpy()[0], net_demand, pd_stations_all, pd_stations_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9535b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Margin(network, pd_stations,year, system_reserve_requirment, year_baseline=None):\n",
    "    if year > 2020:\n",
    "        year = year_baseline\n",
    "    file = '../data/power stations/power_stations_locations_' + str(year) + '.csv'\n",
    "    power_stations = pd.read_csv(file, encoding='unicode_escape')\n",
    "    \n",
    "    de_conversion_csv = pd.read_csv('../data/LOLE/de_conversion_type.csv',index_col=0)\n",
    "    de_conversion_dict = de_conversion_csv.to_dict()['1']\n",
    "    \n",
    "    de_rate = pd.read_csv('../data/LOLE/de_rate.csv',index_col=0)\n",
    "    de_rate = de_rate.to_dict()['De-Rate']\n",
    "    \n",
    "    generators_name_list = network.generators.index.tolist() ##\n",
    "    \n",
    "    #  generator units' breakdown rate time-series dataframe: generators_rate\n",
    "    generators_rate_col = generators_name_list\n",
    "    generators_rate_index = network.snapshots.copy()\n",
    "    generators_rate = pd.DataFrame(columns=generators_rate_col, index=generators_rate_index) \n",
    "    generators_rate.apply(lambda r: get_rate(r, generators_name_list, network.generators.carrier, de_conversion_dict, power_stations, de_rate), axis = 1)\n",
    "    \n",
    "    # storage units' breakdown rate time-series dataframe: storage_rate\n",
    "    storage_units_name_list = network.storage_units.index.tolist() \n",
    "    storage_units_rate_col = storage_units_name_list\n",
    "    storage_units_rate_index = network.snapshots.copy()\n",
    "    storage_units_rate = pd.DataFrame(columns=storage_units_rate_col, index=storage_units_rate_index) ##\n",
    "    storage_units_rate.apply(lambda r: get_rate(r, storage_units_name_list, network.storage_units.carrier, de_conversion_dict, power_stations, de_rate), axis = 1)\n",
    "    \n",
    "    # all units' breakdown rate\n",
    "    pd_rate = pd.concat([generators_rate, storage_units_rate], axis=1) \n",
    "    \n",
    "    # caculate time series of weather dependent generators' outputs from input data \n",
    "\n",
    "    pd_installed_capacity = pd.concat([network.generators.p_nom, network.storage_units.p_nom], axis=0)\n",
    "    de_rated_capacity = pd_installed_capacity * pd_rate\n",
    "    margin = de_rated_capacity.sum(axis =1)[0] - network.loads_t.p_set.sum(axis=1) - system_reserve_requirment # reserve\n",
    "\n",
    "    # index = pd.concat([network.generators, network.storage_units])[~pd.concat([network.generators, network.storage_units]).carrier.isin[]]\n",
    "    \n",
    "    return de_rated_capacity, margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca0cc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_generators(installed_capacity, breakdwon_rate, num = None, value = 0, Round = False, Print = False):\n",
    "    if num == None:\n",
    "        num = installed_capacity.shape[0]\n",
    "    sorted_capacity = np.sort(installed_capacity[installed_capacity >= value])\n",
    "    boundary = sorted_capacity[max(sorted_capacity.shape[0] - num, 0)]\n",
    "    large_capacity = np.copy(installed_capacity[installed_capacity >= boundary])\n",
    "    large_breakdwon_rate = np.copy(breakdwon_rate[installed_capacity >= boundary])\n",
    "    expect_small_capacity = sum(installed_capacity[installed_capacity < boundary] * (1 - breakdwon_rate[installed_capacity < boundary]))\n",
    "    if Round:\n",
    "        large_capacity = np.rint(large_capacity)\n",
    "    if Print:\n",
    "        print('Number of laege generators: ' + str(large_capacity.shape[0]))\n",
    "        print('Boundary: ' + str(boundary))\n",
    "    \n",
    "    return large_capacity, large_breakdwon_rate, expect_small_capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e8ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_add(A,B):\n",
    "    for key,value in B.items():\n",
    "        try:\n",
    "            A[key] += value\n",
    "        except:\n",
    "            A[key] = value\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aec1e14",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def probability_function(capacity, breakdwon_rate):\n",
    "    pdf = dict()\n",
    "    pdf[0] = 1\n",
    "\n",
    "    for i in range(capacity.shape[0]):\n",
    "        prob_down = dict()\n",
    "        prob_up = dict()\n",
    "    \n",
    "        for key,value in pdf.items():\n",
    "            avail_value = np.float64(key)+capacity[i]\n",
    "            try:\n",
    "                prob_up[avail_value] += value * (1-breakdwon_rate[i])\n",
    "            except:\n",
    "                prob_up[avail_value] = value * (1-breakdwon_rate[i])\n",
    "            try:\n",
    "                prob_down[key] += value * breakdwon_rate[i]\n",
    "            except:\n",
    "                prob_down[key] = value * breakdwon_rate[i]\n",
    "        pdf = dict_add(prob_up,prob_down)\n",
    "    pdf = dict(sorted(pdf.items(),key=lambda d:d[0]))\n",
    "    xx = sorted(pdf)\n",
    "    yy = np.zeros(len(xx))\n",
    "    cdf = np.zeros(len(xx))\n",
    "    cdf_i = 0\n",
    "    for i in range(len(pdf)):\n",
    "        key = xx[i]\n",
    "        yy[i] = pdf[key]\n",
    "        cdf_i += yy[i]\n",
    "        cdf[i] = cdf_i\n",
    "    return xx, yy, pdf, cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b99e907",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def rate_table(nuclear=True):\n",
    "    bd_conversion_type = [['Coal', 'Nuclear', 'Oil', 'Wind Offshore', 'Wind Onshore', 'Solar Photovoltaics', 'Large Hydro', 'Small Hydro', 'Anaerobic Digestion', 'EfW Incineration', 'Landfill Gas', 'Sewage Sludge Digestion', 'Shoreline Wave', 'Tidal Barrage and Tidal Stream', 'Biomass (co-firing)', 'Biomass (dedicated)','Pumped Storage Hydroelectric', 'Battery', 'Compressed Air', 'Liquid Air', 'Interconnector', 'Englandconnector',\n",
    "                       'CCS Gas', 'CCS Biomass', 'Hydrogen', 'Unmet Load', 'Tidal lagoon', 'Tidal stream', 'Wave power', 'Waste'],\n",
    "                      ['Coal', 'Nuclear', 'Simil-OCGT', 'Weather Dependent', 'Weather Dependent', 'Weather Dependent', 'Hydro', 'Hydro', 'Biomass', 'Biomass', 'Biomass', 'Biomass', 'Excluded', 'Excluded', 'Biomass', 'Biomass','Pumped storage', 'Battery', 'Simil-CCGT', 'Simil-CCGT', 'Interconnector', 'Englandconnector',\n",
    "                       'Simil-CCGT', 'Biomass', 'Hydrogen', 'Excluded', 'Excluded', 'Excluded', 'Excluded', 'Biomass']]\n",
    "    bd_conversion_type_csv = pd.DataFrame(bd_conversion_type).T\n",
    "\n",
    "    breakdowwn_rate = {\n",
    "        'Coal': 0.1,\n",
    "        'CCGT': 0.06,\n",
    "        'Simil-CCGT': 0.06,\n",
    "        'Hydrogen': 0.06,\n",
    "        'Nuclear': 0.1,\n",
    "        'OCGT': 0.07,\n",
    "        'Simil-OCGT': 0.06, \n",
    "        'Biomass': 0.06,\n",
    "        'Hydro': 0.08,\n",
    "        'Wind': 0.16,\n",
    "        'Pumped storage': 0.03, # arbitrary, need to update\n",
    "        'Interconnector': 0.2,\n",
    "        'Englandconnector': 0.36,\n",
    "        'Weather Dependent': 0,\n",
    "        'Excluded': 1\n",
    "    }\n",
    "\n",
    "    if nuclear == False:\n",
    "        breakdowwn_rate['Nuclear'] = 1\n",
    "\n",
    "    br_csv = pd.DataFrame.from_dict(breakdowwn_rate,orient='index',columns=['Breakdown Rate'])\n",
    "    br_csv = br_csv.reset_index().rename(columns = {'index':'Type'})\n",
    "\n",
    "    # breakdowwn_rate_battery = {\n",
    "    #     '0.5h': 1-0.1789,\n",
    "    #     '1.0h': 1-0.3644,\n",
    "    #     '1.5h': 1-0.5228,\n",
    "    #     '2.0h': 1-0.6479,\n",
    "    #     '2.5h': 1-0.7547,\n",
    "    #     '3.0h': 1-0.8203,\n",
    "    #     '3.5h': 1-0.8575,\n",
    "    #     '4.0h': 1-0.9611 # 4+h\n",
    "    # }\n",
    "\n",
    "    breakdowwn_rate_battery = {\n",
    "        '0.5h': 0.1789,\n",
    "        '1.0h': 0.3644,\n",
    "        '1.5h': 0.5228,\n",
    "        '2.0h': 0.6479,\n",
    "        '2.5h': 0.7547,\n",
    "        '3.0h': 0.8203,\n",
    "        '3.5h': 0.8575,\n",
    "        '4.0h': 0.9611 # 4+h\n",
    "    }\n",
    "    \n",
    "    brb_csv = pd.DataFrame.from_dict(breakdowwn_rate_battery,orient='index',columns=['Breakdown Rate'])\n",
    "    brb_csv = brb_csv.reset_index().rename(columns = {'index':'Duration'})\n",
    "\n",
    "    de_conversion_type = [['Coal', 'Nuclear', 'Oil', 'Wind Offshore', 'Wind Onshore', 'Solar Photovoltaics', 'Large Hydro', 'Small Hydro', 'Anaerobic Digestion', 'EfW Incineration', 'Landfill Gas', 'Sewage Sludge Digestion', 'Shoreline Wave', 'Tidal Barrage and Tidal Stream', 'Biomass (co-firing)', 'Biomass (dedicated)','Pumped Storage Hydroelectric', 'Battery', 'Compressed Air', 'Liquid Air', 'Interconnector', 'Englandconnector', \n",
    "                       'CCS Gas', 'CCS Biomass', 'Hydrogen', 'Unmet Load', 'Tidal lagoon', 'Tidal stream', 'Wave power','Waste'],\n",
    "                      ['Coal', 'Nuclear', 'OCGT', 'Wind', 'Wind', 'Solar', 'Hydro', 'Hydro', 'Waste', 'Waste', 'Waste', 'Waste', 'Marine', 'Marine', 'Biomass', 'Biomass','Pumped storage', 'Battery storage', 'OCGT', 'OCGT', 'Interconnector', 'Interconnector',\n",
    "                       'CCGT', 'Biomass', 'CCGT', 'Excluded', 'Marine', 'Marine', 'Marine','Waste']]\n",
    "    de_conversion_type_csv = pd.DataFrame(de_conversion_type).T\n",
    "\n",
    "    de_rate = {\n",
    "        'Biomass': 0.88,\n",
    "        'Waste': 0.745, # average for various\n",
    "        'Coal': 0.76,\n",
    "        'CCGT': 0.913, # CHP/cogeneration \n",
    "        'OCGT': 0.952, # gas & diesel reciprocating engines\n",
    "        'Nuclear': 0.744,\n",
    "        'Battery storage': 0.597,\n",
    "        'Pumped storage': 0.952,\n",
    "        'Hydro': 0.911,\n",
    "        'Solar': 0.022,\n",
    "        'Marine': 0.22,\n",
    "        'Wind': 0.174, #offshore & onshore\n",
    "        'DSR': 0.715,\n",
    "        'Interconnector': 0.099,\n",
    "        'Excluded': 0\n",
    "    }\n",
    "\n",
    "    if nuclear == False:\n",
    "        de_rate['Nuclear'] = 0\n",
    "\n",
    "    de_csv = pd.DataFrame.from_dict(de_rate,orient='index',columns=['De-Rate'])\n",
    "    de_csv = de_csv.reset_index().rename(columns = {'index':'Type'})\n",
    "\n",
    "    if not os.path.exists('../data/LOLE'):\n",
    "        os.makedirs('../data/LOLE')\n",
    "    bd_conversion_type_csv.to_csv('../data/LOLE/bd_conversion_type.csv',index=False)\n",
    "    br_csv.to_csv('../data/LOLE/breakdown_rate.csv',index=False)\n",
    "    brb_csv.to_csv('../data/LOLE/breakdowwn_rate_battery.csv',index=False)\n",
    "    de_conversion_type_csv.to_csv('../data/LOLE/de_conversion_type.csv',index=False)\n",
    "    de_csv.to_csv('../data/LOLE/de_rate.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102c5f97",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def B6_scaling(year, file_path):\n",
    "    pd_lines = pd.read_csv(file_path, index_col=0)\n",
    "    B6_capacity_data = {'2021': 6100,\n",
    "                        '2025': 7000,\n",
    "                        '2030': 11500,\n",
    "                        '2035': 16900,\n",
    "                        '2040': 16900,\n",
    "                        '2045': 16900}\n",
    "    B6_capacity = B6_capacity_data[str(year)]\n",
    "\n",
    "    # scale the B6 lines to system transformation economy RT\n",
    "    B6 = pd_lines.at[17, 's_nom'] + pd_lines.at[18, 's_nom'] + pd_lines.at[23, 's_nom'] + pd_lines.at[24, 's_nom'] + pd_lines.at[16, 's_nom']\n",
    "    # network.lines\n",
    "    scaling_factor = B6_capacity / B6\n",
    "    pd_lines.s_nom *= scaling_factor\n",
    "    # B6_scaled = pd_lines.at[17, 's_nom'] + pd_lines.at[18, 's_nom'] + pd_lines.at[23, 's_nom'] + pd_lines.at[24, 's_nom'] + pd_lines.at[16, 's_nom']\n",
    "    # print(str(year) + ' : ' + str(B6_scaled))\n",
    "    pd_lines.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ff8ea4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def loads_leap_year():\n",
    "    pd_load = pd.read_csv('LOPF_data/loads-p_set.csv',index_col=0)\n",
    "\n",
    "    pd_load.index = pd.to_datetime(pd_load.index)\n",
    "\n",
    "    pd_load_1 = pd_load[pd_load.index.month <= 2]\n",
    "    pd_load_2 = pd_load[((pd_load.index.month == 2) & (pd_load.index.day == 28))]\n",
    "    pd_load_2.index = [_.replace(day=29) for _ in pd_load_2.index.to_list()]\n",
    "    pd_load_3 = pd_load[pd_load.index.month > 2]\n",
    "    pd_load_new = pd.concat([pd_load_1, pd_load_2, pd_load_3])\n",
    "\n",
    "    pd_load_new.to_csv('LOPF_data/loads-p_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc346610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(year, scenario, demand_dataset='eload', year_baseline = 2020, system_reserve_requirment = 1200, step=100, nuclear=True):\n",
    "    start = str(year) + '-01-01 00:00:00'\n",
    "    end = str(year) + '-12-31 23:30:00'\n",
    "    time_step = 1.\n",
    "\n",
    "    if nuclear == False:\n",
    "        rate_table(nuclear=False)\n",
    "\n",
    "    try:\n",
    "        data_reader_writer.data_writer(start, end, time_step, year, demand_dataset=demand_dataset, year_baseline=year_baseline,\n",
    "            scenario=scenario, FES=2022, merge_generators=True, scale_to_peak=True)\n",
    "    except:\n",
    "        shutil.rmtree('LOPF_data')\n",
    "        os.mkdir('LOPF_data')\n",
    "        data_reader_writer.data_writer(start, end, time_step, year, demand_dataset=demand_dataset, year_baseline=year_baseline,\n",
    "            scenario=scenario, FES=2022, merge_generators=True, scale_to_peak=True)\n",
    "        \n",
    "    B6_scaling(year, 'LOPF_data/lines.csv')\n",
    "\n",
    "    if year % 4 == 0:\n",
    "        print('add 29/02/'+str(year))\n",
    "        loads_leap_year()\n",
    "\n",
    "    scotland_network.scotland()\n",
    "    scotland_network.interconnector()\n",
    "\n",
    "    network = pypsa.Network()\n",
    "    network.import_from_csv_folder('LOPF_data_Scotland')\n",
    "\n",
    "    buses_scotland = ['Beauly', 'Peterhead', 'Errochty', 'Denny/Bonnybridge', 'Neilston', 'Strathaven', 'Torness', 'Eccles']\n",
    "    for bus in buses_scotland:\n",
    "        # derate gas to 0% of capacity across Scotland\n",
    "        if year >= 2030:\n",
    "            network.generators.loc[(network.generators['bus'] == bus) & (network.generators['carrier'] == 'CCS Gas'), \"p_nom\"] *= 0.\n",
    "            network.generators.loc[(network.generators['bus'] == bus) & (network.generators['carrier'] == 'Natural Gas'), \"p_nom\"] *= 0.\n",
    "        # derate hydrogen to 0% of capacity across Scotland\n",
    "        network.generators.loc[(network.generators['bus'] == bus) & (network.generators['carrier'] == 'Hydrogen'), \"p_nom\"] *= 0.\n",
    "        # limit biomass to 230MW capacity across Scotland 2040 onwards\n",
    "        if year >= 2040:\n",
    "            network.generators.loc[(network.generators['bus'] == bus) & (network.generators['carrier'] == 'Biomass (dedicated)'), \"p_nom\"] = 0.\n",
    "            network.generators.loc[(network.generators['bus'] == bus) & (network.generators['carrier'] == 'CCS Biomass'), \"p_nom\"] = 0.\n",
    "\n",
    "    peak_demand_data = {'2021': 4600,\n",
    "                        '2025': 4800,\n",
    "                        '2030': 5900,\n",
    "                        '2035': 8000,\n",
    "                        '2040': 10200,\n",
    "                        '2045': 11300}\n",
    "    unscaled_peak = network.loads_t.p_set[buses_scotland].sum(axis=1).max()\n",
    "    load_scale = peak_demand_data[str(year)] / unscaled_peak\n",
    "\n",
    "    network.loads_t.p_set.loc[:, buses_scotland] *= load_scale\n",
    "    \n",
    "    output_margin = pd.DataFrame(index=network.snapshots)\n",
    "    output_lolp = pd.DataFrame(columns=['peak_lolp', 'lole', 'lole_week'])\n",
    "    output_lolp_self = pd.DataFrame(columns=['peak_lolp', 'lole', 'lole_week'])\n",
    "    lole_loop = pd.DataFrame(columns=[i*step for i in range(round(10000/step))])\n",
    "\n",
    "    installed_capacity, breakdwon_rate, net_demand, pd_stations_all, pd_stations_w = LOLP(network, year, year_baseline=year_baseline)\n",
    "    de_rated_capacity, margin = Margin(network, pd_stations_all, year, system_reserve_requirment, year_baseline=year_baseline)\n",
    "\n",
    "    output_margin['margin'] = margin\n",
    "    output_margin['demand'] = network.loads_t.p_set.sum(axis=1)\n",
    "    output_margin['net_demand'] = net_demand\n",
    "    output_margin['weather_dependent'] = pd_stations_w.sum(axis=1)\n",
    "\n",
    "    print('De_rated_capacity in ' + str(year) + ': ' + str(de_rated_capacity.sum(axis =1)[0]))\n",
    "    print('System margin:')\n",
    "    print(margin.describe())\n",
    "    print('Demand:')\n",
    "    print(network.loads_t.p_set.sum(axis=1).describe())\n",
    "    print('Net demand:')\n",
    "    print(pd.Series(net_demand).describe())\n",
    "\n",
    "    if os.path.exists('../data/LOLE/peak_demand.csv'):\n",
    "        pd_peak_demand = pd.read_csv('../data/LOLE/peak_demand.csv', index_col=0)\n",
    "    else:\n",
    "        pd_peak_demand = pd.DataFrame(columns=['demand'])\n",
    "    pd_peak_demand.loc[year] = {'demand': network.loads_t.p_set.sum(axis=1).max()}\n",
    "    pd_peak_demand.to_csv('../data/LOLE/peak_demand.csv')\n",
    "\n",
    "    generators_p_nom_scotland = pd.concat([network.generators, network.storage_units]).p_nom.groupby(\n",
    "        pd.concat([network.generators, network.storage_units]).carrier).sum().sort_values()\n",
    "    if year > 2020:\n",
    "        generators_p_nom_scotland.drop(['Unmet Load', 'CCS Biomass'], inplace=True)\n",
    "    generators_p_nom_scotland.drop(generators_p_nom_scotland[generators_p_nom_scotland < 50].index, inplace=True)\n",
    "    print(generators_p_nom_scotland)\n",
    "    generators_p_nom_scotland.to_csv('../data/LOLE/generators_p_nom_'+str(year)+'_'+re.sub(\"[^A-Z]\",\"\",scenario)+'.csv')\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(generators_p_nom_scotland.index, generators_p_nom_scotland.values / 1000)\n",
    "    plt.xticks(generators_p_nom_scotland.index, rotation=90)\n",
    "    plt.ylabel('GW')\n",
    "    plt.grid(color='grey', linewidth=1, axis='both', alpha=0.5)\n",
    "    # plt.title('Scotland installed generation capacity in year ' + str(year))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/LOLE/Installed_capacity_'+str(year)+'_'+re.sub(\"[^A-Z]\",\"\",scenario)+'.png', dpi = 600)\n",
    "    plt.show()\n",
    "\n",
    "    pd_de_rated_capacity = pd.concat([network.generators, network.storage_units])\n",
    "    pd_de_rated_capacity['de_rated_capacit'] = de_rated_capacity.loc[de_rated_capacity.index[0]].tolist()\n",
    "    pd_de_rated_capacity = pd_de_rated_capacity.de_rated_capacit.groupby(\n",
    "        pd_de_rated_capacity.carrier).sum().sort_values()\n",
    "    if year > 2020:\n",
    "        pd_de_rated_capacity.drop(['Unmet Load', 'CCS Biomass'], inplace=True)\n",
    "    pd_de_rated_capacity.drop(pd_de_rated_capacity[pd_de_rated_capacity < 50].index, inplace=True)\n",
    "    print(pd_de_rated_capacity)\n",
    "    pd_de_rated_capacity.to_csv('../data/LOLE/de_rated_capacity_'+str(year)+'_'+re.sub(\"[^A-Z]\",\"\",scenario)+'.csv')\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(pd_de_rated_capacity.index, pd_de_rated_capacity.values / 1000)\n",
    "    plt.xticks(pd_de_rated_capacity.index, rotation=90)\n",
    "    plt.ylabel('GW')\n",
    "    plt.grid(color='grey', linewidth=1, axis='both', alpha=0.5)\n",
    "    # plt.title('Scotland installed de-rate capacity in year ' + str(year))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/LOLE/De-rate_capacity_'+str(year)+'_'+re.sub(\"[^A-Z]\",\"\",scenario)+'.png', dpi = 600)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    large_capacity, large_breakdwon_rate, expect_small_capacity = split_generators(installed_capacity, breakdwon_rate, value = 0, Round=True)\n",
    "    xx, yy, pdf, cdf = probability_function(large_capacity, large_breakdwon_rate)\n",
    "\n",
    "    pd_cdf = pd.DataFrame()\n",
    "    pd_cdf['xx']=xx\n",
    "    pd_cdf['yy']=cdf\n",
    "    pd_cdf.to_csv('../data/LOLE/cdf_'+str(year)+'_'+re.sub(\"[^A-Z]\",\"\",scenario)+'.csv')\n",
    "\n",
    "    # plt.plot(xx,yy)\n",
    "    # plt.figure(figsize=(6,8))\n",
    "    # plt.plot(xx,yy)\n",
    "    # plt.xlim(max(xx)*.6,max(xx)*1.1)\n",
    "\n",
    "    # int_x = [round(x/100)*100 for x in xx]\n",
    "    # plt.figure(figsize=(6,8))\n",
    "    # plt.plot(int_x,yy)\n",
    "    # plt.xlim(max(xx)*.6,max(xx)*1.1)\n",
    "\n",
    "    # plt.plot(xx,cdf)\n",
    "    # plt.show()\n",
    "\n",
    "    lolp = list()\n",
    "    for i in range(len(net_demand)):\n",
    "        lolp.append(yy[xx<net_demand[i] - expect_small_capacity + system_reserve_requirment].sum())\n",
    "    lole = sum(lolp)\n",
    "    lolp_base = lolp\n",
    "   \n",
    "    peak_demand = network.loads_t.p_set.sum(axis=1).max()\n",
    "    index_peak_demand = np.where(network.loads_t.p_set.sum(axis=1).to_numpy() == peak_demand)[0][0]\n",
    "    pd_peakload_period = pd.DataFrame(pd_stations_w.sum(axis=1),columns=['weather dependent capacity'])\n",
    "    pd_peakload_period = pd_peakload_period[((pd_peakload_period.index.month<4)|(pd_peakload_period.index.month>10)) &\n",
    "                (pd_peakload_period.index.weekday<6) &\n",
    "                (pd_peakload_period.index.hour>6) & (pd_peakload_period.index.hour<20)]\n",
    "    wdc = pd_peakload_period['weather dependent capacity'].to_numpy()\n",
    "\n",
    "    lolp_p = 0\n",
    "    for i in range(wdc.shape[0]):\n",
    "        lolp_p += yy[xx<peak_demand-wdc[i]-expect_small_capacity+system_reserve_requirment].sum()/wdc.shape[0]\n",
    "\n",
    "    output_lolp.loc['Base case'] = {'peak_lolp':lolp_p, 'lole':lole, 'lole_week': lole}\n",
    "\n",
    "    lole_list = [lole]\n",
    "    i_ = 0\n",
    "    while (lole > 0.3):\n",
    "        i_ += 1\n",
    "        lolp = list()\n",
    "        for i in range(len(net_demand)):\n",
    "            lolp.append(yy[xx<net_demand[i]-expect_small_capacity+system_reserve_requirment-i_*step].sum())\n",
    "        lole = sum(lolp)\n",
    "        lole_list.append(lole)\n",
    "        print(f'for {i_*step}MW increased firm capacity, lole is {lole}')\n",
    "    lole_loop.loc['Base case'] = dict([[i*step, lole_list[i]] for i in range(i_+1)])\n",
    "    \n",
    "\n",
    "\n",
    "    # ### 2.1 Largest offshore wind farm failure \n",
    "    largest_windfarm = network.generators_t.p_max_pu[network.generators[network.generators.carrier.isin(['Wind Offshore'])].p_nom.idxmax()] \\\n",
    "        * network.generators[network.generators.carrier.isin(['Wind Onshore', 'Wind Offshore'])].p_nom.max()\n",
    "    pd_peakload_period['largest windfarm supply'] = largest_windfarm[largest_windfarm.index.isin(pd_peakload_period.index)]\n",
    "    lws = pd_peakload_period['largest windfarm supply'].to_numpy()\n",
    "    lolp = list()\n",
    "    for i in range(len(net_demand)):\n",
    "        lolp.append(yy[xx<net_demand[i] + largest_windfarm[i] - expect_small_capacity + system_reserve_requirment].sum())\n",
    "    lole = sum(lolp)\n",
    "    lole_week = sum(lolp_base[: index_peak_demand-85] + lolp[index_peak_demand-85: index_peak_demand+84] + lolp_base[index_peak_demand+84:])\n",
    "\n",
    "    lolp_p = 0\n",
    "    for i in range(wdc.shape[0]):\n",
    "        lolp_p += yy[xx<peak_demand-wdc[i]+lws[i]-expect_small_capacity+system_reserve_requirment].sum()/wdc.shape[0]\n",
    "\n",
    "    output_lolp.loc['Largest offshore failure'] = {'peak_lolp':lolp_p, 'lole':lole, 'lole_week': lole_week}\n",
    "\n",
    "    lole_list = [lole]\n",
    "    i_ = 0\n",
    "    while (lole > 0.3):\n",
    "        i_ += 1\n",
    "        lolp = list()\n",
    "        for i in range(len(net_demand)):\n",
    "            lolp.append(yy[xx<net_demand[i]-expect_small_capacity+system_reserve_requirment-i_*step].sum())\n",
    "        lole = sum(lolp)\n",
    "        lole_list.append(lole)\n",
    "        print(f'for {i_*step}MW increased firm capacity, lole is {lole}')\n",
    "    lole_loop.loc['Largest offshore failure'] = dict([[i*step, lole_list[i]] for i in range(i_+1)])\n",
    "\n",
    "\n",
    "    # ### 2.2 Long period of low RES power scenario\n",
    "    net_demand = network.loads_t.p_set.sum(axis=1) - pd_stations_w.sum(axis=1) * 0.8\n",
    "    lolp = list()\n",
    "    for i in range(len(net_demand)):\n",
    "        lolp.append(yy[xx<net_demand[i] - expect_small_capacity + system_reserve_requirment].sum())\n",
    "    lole = sum(lolp)\n",
    "    lole_week = sum(lolp_base[: index_peak_demand-85] + lolp[index_peak_demand-85: index_peak_demand+84] + lolp_base[index_peak_demand+84:])\n",
    "\n",
    "    lolp_p = 0\n",
    "    for i in range(wdc.shape[0]):\n",
    "        lolp_p += yy[xx<peak_demand-wdc[i]*0.8-expect_small_capacity+system_reserve_requirment].sum()/wdc.shape[0]\n",
    "    \n",
    "    output_lolp.loc['Low RES power'] = {'peak_lolp':lolp_p, 'lole':lole, 'lole_week': lole_week}\n",
    "\n",
    "    lole_list = [lole]\n",
    "    i_ = 0\n",
    "    while (lole > 0.3):\n",
    "        i_ += 1\n",
    "        lolp = list()\n",
    "        for i in range(len(net_demand)):\n",
    "            lolp.append(yy[xx<net_demand[i]-expect_small_capacity+system_reserve_requirment-i_*step].sum())\n",
    "        lole = sum(lolp)\n",
    "        lole_list.append(lole)\n",
    "        print(f'for {i_*step}MW increased firm capacity, lole is {lole}')\n",
    "    lole_loop.loc['Low RES power'] = dict([[i*step, lole_list[i]] for i in range(i_+1)])\n",
    "\n",
    "\n",
    "    # ### 1 Gas supply issues \n",
    "    installed_capacity, breakdwon_rate, net_demand, pd_stations_all, pd_stations_w = LOLP(network, year, year_baseline=year_baseline, failures_type=['CCGT','OCGT'], failures_rate=0.)\n",
    "    large_capacity, large_breakdwon_rate, expect_small_capacity = split_generators(installed_capacity, breakdwon_rate, value = 0, Round=True)\n",
    "    xx, yy, pdf, cdf = probability_function(large_capacity, large_breakdwon_rate)\n",
    "\n",
    "    lolp = list()\n",
    "    for i in range(len(net_demand)):\n",
    "        lolp.append(yy[xx<net_demand[i] - expect_small_capacity + system_reserve_requirment].sum())\n",
    "    lole = sum(lolp)\n",
    "    lole_week = sum(lolp_base[: index_peak_demand-85] + lolp[index_peak_demand-85: index_peak_demand+84] + lolp_base[index_peak_demand+84:])\n",
    "\n",
    "    lolp_p = 0\n",
    "    for i in range(wdc.shape[0]):\n",
    "        lolp_p += yy[xx<peak_demand-wdc[i]-expect_small_capacity+system_reserve_requirment].sum()/wdc.shape[0]\n",
    "\n",
    "    output_lolp.loc['Gas supply issues'] = {'peak_lolp':lolp_p, 'lole':lole, 'lole_week': lole_week}\n",
    "\n",
    "    lole_list = [lole]\n",
    "    i_ = 0\n",
    "    while (lole > 0.3):\n",
    "        i_ += 1\n",
    "        lolp = list()\n",
    "        for i in range(len(net_demand)):\n",
    "            lolp.append(yy[xx<net_demand[i]-expect_small_capacity+system_reserve_requirment-i_*step].sum())\n",
    "        lole = sum(lolp)\n",
    "        lole_list.append(lole)\n",
    "        print(f'for {i_*step}MW increased firm capacity, lole is {lole}')\n",
    "    lole_loop.loc['Gas supply issues'] = dict([[i*step, lole_list[i]] for i in range(i_+1)])\n",
    "\n",
    "\n",
    "    # ### 3.1 Storage failures\n",
    "    installed_capacity, breakdwon_rate, net_demand, pd_stations_all, pd_stations_w = LOLP(network, year, year_baseline=year_baseline, failures_type='Battery', failures_rate=0.)\n",
    "    large_capacity, large_breakdwon_rate, expect_small_capacity = split_generators(installed_capacity, breakdwon_rate, value = 0, Round=True)\n",
    "    xx, yy, pdf, cdf = probability_function(large_capacity, large_breakdwon_rate)\n",
    "\n",
    "    lolp = list()\n",
    "    for i in range(len(net_demand)):\n",
    "        lolp.append(yy[xx<net_demand[i] - expect_small_capacity + system_reserve_requirment].sum())\n",
    "\n",
    "    lole = sum(lolp)\n",
    "    lole_week = sum(lolp_base[: index_peak_demand-85] + lolp[index_peak_demand-85: index_peak_demand+84] + lolp_base[index_peak_demand+84:])\n",
    "\n",
    "    lolp_p = 0\n",
    "    for i in range(wdc.shape[0]):\n",
    "        lolp_p += yy[xx<peak_demand-wdc[i]-expect_small_capacity+system_reserve_requirment].sum()/wdc.shape[0]\n",
    "\n",
    "    output_lolp.loc['Storage failures'] = {'peak_lolp':lolp_p, 'lole':lole, 'lole_week': lole_week}\n",
    "\n",
    "    lole_list = [lole]\n",
    "    i_ = 0\n",
    "    while (lole > 0.3):\n",
    "        i_ += 1\n",
    "        lolp = list()\n",
    "        for i in range(len(net_demand)):\n",
    "            lolp.append(yy[xx<net_demand[i]-expect_small_capacity+system_reserve_requirment-i_*100].sum())\n",
    "        lole = sum(lolp)\n",
    "        lole_list.append(lole)\n",
    "        print(f'for {i_*step}MW increased firm capacity, lole is {lole}')\n",
    "    lole_loop.loc['Storage failures'] = dict([[i*step, lole_list[i]] for i in range(i_+1)])\n",
    "\n",
    "\n",
    "    # ### 3.2 Interconnector failure\n",
    "    installed_capacity, breakdwon_rate, net_demand, pd_stations_all, pd_stations_w = LOLP(network, year, year_baseline=year_baseline, failures_type='Interconnector', failures_rate=0.)\n",
    "    large_capacity, large_breakdwon_rate, expect_small_capacity = split_generators(installed_capacity, breakdwon_rate, value = 0, Round=True)\n",
    "    xx, yy, pdf, cdf = probability_function(large_capacity, large_breakdwon_rate)\n",
    "    \n",
    "    lolp = list()\n",
    "    for i in range(len(net_demand)):\n",
    "        lolp.append(yy[xx<net_demand[i] - expect_small_capacity + system_reserve_requirment].sum())\n",
    "    lole = sum(lolp)\n",
    "    lole_week = sum(lolp_base[: index_peak_demand-85] + lolp[index_peak_demand-85: index_peak_demand+84] + lolp_base[index_peak_demand+84:])\n",
    "\n",
    "    lolp_p = 0\n",
    "    for i in range(wdc.shape[0]):\n",
    "        lolp_p += yy[xx<peak_demand-wdc[i]-expect_small_capacity+system_reserve_requirment].sum()/wdc.shape[0]\n",
    "\n",
    "    output_lolp.loc['Interconnector failure'] = {'peak_lolp':lolp_p, 'lole':lole, 'lole_week': lole_week}\n",
    "\n",
    "    lole_list = [lole]\n",
    "    i_ = 0\n",
    "    while (lole > 0.3):\n",
    "        i_ += 1\n",
    "        lolp = list()\n",
    "        for i in range(len(net_demand)):\n",
    "            lolp.append(yy[xx<net_demand[i]-expect_small_capacity+system_reserve_requirment-i_*step].sum())\n",
    "        lole = sum(lolp)\n",
    "        lole_list.append(lole)\n",
    "        print(f'for {i_*step}MW increased firm capacity, lole is {lole}')\n",
    "    lole_loop.loc['Interconnector failure'] = dict([[i*step, lole_list[i]] for i in range(i_+1)])\n",
    "\n",
    "\n",
    "     # ### 3.3 Scot-Eng links failure\n",
    "    installed_capacity, breakdwon_rate, net_demand, pd_stations_all, pd_stations_w = LOLP(network, year, year_baseline=year_baseline, failures_type='Englandconnector', failures_rate=0.)\n",
    "    large_capacity, large_breakdwon_rate, expect_small_capacity = split_generators(installed_capacity, breakdwon_rate, value = 0, Round=True)\n",
    "    xx, yy, pdf, cdf = probability_function(large_capacity, large_breakdwon_rate)\n",
    "    \n",
    "    lolp = list()\n",
    "    for i in range(len(net_demand)):\n",
    "        lolp.append(yy[xx<net_demand[i] - expect_small_capacity + system_reserve_requirment].sum())\n",
    "    lole = sum(lolp)\n",
    "    lole_week = sum(lolp_base[: index_peak_demand-85] + lolp[index_peak_demand-85: index_peak_demand+84] + lolp_base[index_peak_demand+84:])\n",
    "\n",
    "    lolp_p = 0\n",
    "    for i in range(wdc.shape[0]):\n",
    "        lolp_p += yy[xx<peak_demand-wdc[i]-expect_small_capacity+system_reserve_requirment].sum()/wdc.shape[0]\n",
    "\n",
    "    output_lolp.loc['B6 failure'] = {'peak_lolp':lolp_p, 'lole':lole, 'lole_week': lole_week}\n",
    "\n",
    "    lole_list = [lole]\n",
    "    i_ = 0\n",
    "    while (lole > 0.3):\n",
    "        i_ += 1\n",
    "        lolp = list()\n",
    "        for i in range(len(net_demand)):\n",
    "            lolp.append(yy[xx<net_demand[i]-expect_small_capacity+system_reserve_requirment-i_*step].sum())\n",
    "        lole = sum(lolp)\n",
    "        lole_list.append(lole)\n",
    "        print(f'for {i_*step}MW increased firm capacity, lole is {lole}')\n",
    "    lole_loop.loc['B6 failure'] = dict([[i*step, lole_list[i]] for i in range(i_+1)])\n",
    "\n",
    "\n",
    "    # ## self-sufficient Scotland\n",
    "    installed_capacity, breakdwon_rate, net_demand, pd_stations_all, pd_stations_w = LOLP(network, year, year_baseline=year_baseline, failures_type=['Interconnector','Englandconnector'], failures_rate=0.)\n",
    "    large_capacity, large_breakdwon_rate, expect_small_capacity = split_generators(installed_capacity, breakdwon_rate, value = 0, Round=True)\n",
    "    xx, yy, pdf, cdf = probability_function(large_capacity, large_breakdwon_rate)\n",
    "\n",
    "    lolp = list()\n",
    "    for i in range(len(net_demand)):\n",
    "        lolp.append(yy[xx<net_demand[i] - expect_small_capacity + system_reserve_requirment].sum())\n",
    "    lole = sum(lolp)\n",
    "    lole_week = sum(lolp_base[: index_peak_demand-85] + lolp[index_peak_demand-85: index_peak_demand+84] + lolp_base[index_peak_demand+84:])\n",
    "    lolp_base = lolp\n",
    "\n",
    "    lolp_p = 0\n",
    "    for i in range(wdc.shape[0]):\n",
    "        lolp_p += yy[xx<peak_demand-wdc[i]-expect_small_capacity+system_reserve_requirment].sum()/wdc.shape[0]\n",
    "\n",
    "    output_lolp.loc['Self-sufficient'] = {'peak_lolp':lolp_p, 'lole':lole, 'lole_week': lole_week}\n",
    "    output_lolp_self.loc['Base case (Self-sufficient)'] = {'peak_lolp':lolp_p, 'lole':lole, 'lole_week': lole}\n",
    "\n",
    "    peak_demand = network.loads_t.p_set.sum(axis=1).max()\n",
    "    index_peak_demand = np.where(network.loads_t.p_set.sum(axis=1).to_numpy() == peak_demand)[0][0]\n",
    "    \n",
    "    lole_list = [lole]\n",
    "    i_ = 0\n",
    "    while (lole > 0.3):\n",
    "        i_ += 1\n",
    "        lolp = list()\n",
    "        for i in range(len(net_demand)):\n",
    "            lolp.append(yy[xx<net_demand[i]-expect_small_capacity+system_reserve_requirment-i_*step].sum())\n",
    "        lole = sum(lolp)\n",
    "        lole_list.append(lole)\n",
    "        print(f'for {i_*step}MW increased firm capacity, lole is {lole}')\n",
    "    lole_loop.loc['Self-sufficient'] = dict([[i*step, lole_list[i]] for i in range(i_+1)])\n",
    "    \n",
    "\n",
    "    #################### THE FOLLOWING ARE ON THE TOP OF SELF-SUFFICENT SCOTLAND ########################\n",
    "\n",
    "    # ### 2.1 Largest offshore wind farm failure \n",
    "    largest_windfarm = network.generators_t.p_max_pu[network.generators[network.generators.carrier.isin(['Wind Offshore'])].p_nom.idxmax()] \\\n",
    "        * network.generators[network.generators.carrier.isin(['Wind Onshore', 'Wind Offshore'])].p_nom.max()\n",
    "    pd_peakload_period['largest windfarm supply'] = largest_windfarm[largest_windfarm.index.isin(pd_peakload_period.index)]\n",
    "    lws = pd_peakload_period['largest windfarm supply'].to_numpy()\n",
    "    lolp = list()\n",
    "    for i in range(len(net_demand)):\n",
    "        lolp.append(yy[xx<net_demand[i] + largest_windfarm[i] - expect_small_capacity + system_reserve_requirment].sum())\n",
    "    lole = sum(lolp)\n",
    "    lole_week = sum(lolp_base[: index_peak_demand-85] + lolp[index_peak_demand-85: index_peak_demand+84] + lolp_base[index_peak_demand+84:])\n",
    "\n",
    "    lolp_p = 0\n",
    "    for i in range(wdc.shape[0]):\n",
    "        lolp_p += yy[xx<peak_demand-wdc[i]+lws[i]-expect_small_capacity+system_reserve_requirment].sum()/wdc.shape[0]\n",
    "\n",
    "    output_lolp_self.loc['Largest offshore failure'] = {'peak_lolp':lolp_p, 'lole':lole, 'lole_week': lole_week}\n",
    "\n",
    "    lole_list = [lole]\n",
    "    i_ = 0\n",
    "    while (lole > 0.3):\n",
    "        i_ += 1\n",
    "        lolp = list()\n",
    "        for i in range(len(net_demand)):\n",
    "            lolp.append(yy[xx<net_demand[i]-expect_small_capacity+system_reserve_requirment-i_*step].sum())\n",
    "        lole = sum(lolp)\n",
    "        lole_list.append(lole)\n",
    "        print(f'for {i_*step}MW increased firm capacity, lole is {lole}')\n",
    "    lole_loop.loc['Self_Largest offshore failure'] = dict([[i*step, lole_list[i]] for i in range(i_+1)])\n",
    "\n",
    "\n",
    "    # ### 2.2 Long period of low RES power scenario\n",
    "    net_demand = network.loads_t.p_set.sum(axis=1) - pd_stations_w.sum(axis=1) * 0.8\n",
    "    lolp = list()\n",
    "    for i in range(len(net_demand)):\n",
    "        lolp.append(yy[xx<net_demand[i] - expect_small_capacity + system_reserve_requirment].sum())\n",
    "    lole = sum(lolp)\n",
    "    lole_week = sum(lolp_base[: index_peak_demand-85] + lolp[index_peak_demand-85: index_peak_demand+84] + lolp_base[index_peak_demand+84:])\n",
    "\n",
    "    lolp_p = 0\n",
    "    for i in range(wdc.shape[0]):\n",
    "        lolp_p += yy[xx<peak_demand-wdc[i]*0.8-expect_small_capacity+system_reserve_requirment].sum()/wdc.shape[0]\n",
    "    \n",
    "    output_lolp_self.loc['Low RES power'] = {'peak_lolp':lolp_p, 'lole':lole, 'lole_week': lole_week}\n",
    "\n",
    "    lole_list = [lole]\n",
    "    i_ = 0\n",
    "    while (lole > 0.3):\n",
    "        i_ += 1\n",
    "        lolp = list()\n",
    "        for i in range(len(net_demand)):\n",
    "            lolp.append(yy[xx<net_demand[i]-expect_small_capacity+system_reserve_requirment-i_*step].sum())\n",
    "        lole = sum(lolp)\n",
    "        lole_list.append(lole)\n",
    "        print(f'for {i_*step}MW increased firm capacity, lole is {lole}')\n",
    "    lole_loop.loc['Self_Low RES power'] = dict([[i*step, lole_list[i]] for i in range(i_+1)])\n",
    "\n",
    "\n",
    "    # ### 1 Gas supply issues \n",
    "    installed_capacity, breakdwon_rate, net_demand, pd_stations_all, pd_stations_w = LOLP(network, year, year_baseline=year_baseline, failures_type=['CCGT', 'OCGT', 'Interconnector','Englandconnector'], failures_rate=0.)\n",
    "    large_capacity, large_breakdwon_rate, expect_small_capacity = split_generators(installed_capacity, breakdwon_rate, value = 0, Round=True)\n",
    "    xx, yy, pdf, cdf = probability_function(large_capacity, large_breakdwon_rate)\n",
    "\n",
    "    lolp = list()\n",
    "    for i in range(len(net_demand)):\n",
    "        lolp.append(yy[xx<net_demand[i] - expect_small_capacity + system_reserve_requirment].sum())\n",
    "    lole = sum(lolp)\n",
    "    lole_week = sum(lolp_base[: index_peak_demand-85] + lolp[index_peak_demand-85: index_peak_demand+84] + lolp_base[index_peak_demand+84:])\n",
    "\n",
    "    lolp_p = 0\n",
    "    for i in range(wdc.shape[0]):\n",
    "        lolp_p += yy[xx<peak_demand-wdc[i]-expect_small_capacity+system_reserve_requirment].sum()/wdc.shape[0]\n",
    "\n",
    "    output_lolp_self.loc['Gas supply issues'] = {'peak_lolp':lolp_p, 'lole':lole, 'lole_week': lole_week}\n",
    "\n",
    "    lole_list = [lole]\n",
    "    i_ = 0\n",
    "    while (lole > 0.3):\n",
    "        i_ += 1\n",
    "        lolp = list()\n",
    "        for i in range(len(net_demand)):\n",
    "            lolp.append(yy[xx<net_demand[i]-expect_small_capacity+system_reserve_requirment-i_*step].sum())\n",
    "        lole = sum(lolp)\n",
    "        lole_list.append(lole)\n",
    "        print(f'for {i_*step}MW increased firm capacity, lole is {lole}')\n",
    "    lole_loop.loc['Self_Gas supply issues'] = dict([[i*step, lole_list[i]] for i in range(i_+1)])\n",
    "\n",
    "                                       \n",
    "    # ### 3.1 Storage failures\n",
    "    installed_capacity, breakdwon_rate, net_demand, pd_stations_all, pd_stations_w = LOLP(network, year, year_baseline=year_baseline, failures_type=['Battery', 'Interconnector', 'Englandconnector'], failures_rate=0.)\n",
    "    large_capacity, large_breakdwon_rate, expect_small_capacity = split_generators(installed_capacity, breakdwon_rate, value = 0, Round=True)\n",
    "    xx, yy, pdf, cdf = probability_function(large_capacity, large_breakdwon_rate)\n",
    "\n",
    "    lolp = list()\n",
    "    for i in range(len(net_demand)):\n",
    "        lolp.append(yy[xx<net_demand[i] - expect_small_capacity + system_reserve_requirment].sum())\n",
    "\n",
    "    lole = sum(lolp)\n",
    "    lole_week = sum(lolp_base[: index_peak_demand-85] + lolp[index_peak_demand-85: index_peak_demand+84] + lolp_base[index_peak_demand+84:])\n",
    "\n",
    "    lolp_p = 0\n",
    "    for i in range(wdc.shape[0]):\n",
    "        lolp_p += yy[xx<peak_demand-wdc[i]-expect_small_capacity+system_reserve_requirment].sum()/wdc.shape[0]\n",
    "\n",
    "    output_lolp_self.loc['Storage failures'] = {'peak_lolp':lolp_p, 'lole':lole, 'lole_week': lole_week}\n",
    "\n",
    "    lole_list = [lole]\n",
    "    i_ = 0\n",
    "    while (lole > 0.3):\n",
    "        i_ += 1\n",
    "        lolp = list()\n",
    "        for i in range(len(net_demand)):\n",
    "            lolp.append(yy[xx<net_demand[i]-expect_small_capacity+system_reserve_requirment-i_*step].sum())\n",
    "        lole = sum(lolp)\n",
    "        lole_list.append(lole)\n",
    "        print(f'for {i_*step}MW increased firm capacity, lole is {lole}')\n",
    "    lole_loop.loc['Storage failures'] = dict([[i*step, lole_list[i]] for i in range(i_+1)])\n",
    "\n",
    "    if nuclear == False:\n",
    "        rate_table()\n",
    "\n",
    "    output_lolp.to_csv('../data/LOLE/lolp_lole_'+str(year)+'_'+re.sub(\"[^A-Z]\",\"\", scenario)+'.csv')\n",
    "    output_lolp_self.to_csv('../data/LOLE/self_lolp_lole_'+str(year)+'_'+re.sub(\"[^A-Z]\",\"\", scenario)+'.csv')\n",
    "    output_margin.to_csv('../data/LOLE/margin_demand_'+str(year)+'_'+re.sub(\"[^A-Z]\",\"\", scenario)+'.csv')\n",
    "    lole_loop.dropna(axis=1, how='all').T.to_csv('../data/LOLE/lole_loop_'+str(year)+'_'+re.sub(\"[^A-Z]\",\"\", scenario)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bdf440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb627b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main_plot(scenario, year_list):\n",
    "    pd_plot = pd.DataFrame()\n",
    "    pd_plot_self = pd.DataFrame()\n",
    "    md_rate = list()\n",
    "    pd_de_rate = pd.DataFrame()\n",
    "    for year in year_list:\n",
    "        pd_lolp = pd.read_csv('../data/LOLE/lolp_lole_'+str(year)+'_'+re.sub(\"[^A-Z]\",\"\", scenario)+'.csv', index_col=0)\n",
    "        pd_lolp.index = pd.MultiIndex.from_arrays([[year]*8, pd_lolp.index.tolist()])\n",
    "        pd_plot = pd.concat([pd_plot, pd_lolp])\n",
    "\n",
    "        pd_lolp_self = pd.read_csv('../data/LOLE/self_lolp_lole_'+str(year)+'_'+re.sub(\"[^A-Z]\",\"\", scenario)+'.csv', index_col=0)\n",
    "        pd_lolp_self.index = pd.MultiIndex.from_arrays([[year]*5, pd_lolp_self.index.tolist()])\n",
    "        pd_plot_self = pd.concat([pd_plot_self, pd_lolp_self])\n",
    "\n",
    "        pd_margin = pd.read_csv('../data/LOLE/margin_demand_'+str(year)+'_'+re.sub(\"[^A-Z]\",\"\", scenario)+'.csv', index_col=0)\n",
    "        max_demand = pd_margin['demand'].max()\n",
    "        min_margin = pd_margin['margin'].min()\n",
    "        md_rate.append(min_margin / (max_demand + min_margin))\n",
    "\n",
    "        pd_de_rate = pd.concat([pd_de_rate, pd.read_csv('../data/LOLE/de_rated_capacity_'+str(year)+'_'+re.sub(\"[^A-Z]\",\"\", scenario)+'.csv', index_col=0).rename(columns={'de_rated_capacit': year})], axis=1).fillna(0)\n",
    "\n",
    "    pd_plot = pd_plot.swaplevel()\n",
    "    pd_plot_self = pd_plot_self.swaplevel()\n",
    "    for case in pd_plot.index.get_level_values(0).drop_duplicates().tolist():\n",
    "        sub_pd = pd_plot.loc[case]\n",
    "        for col in sub_pd.columns.tolist():\n",
    "            plt.figure(figsize=(10,4))\n",
    "            if col == 'lole':\n",
    "                plt.plot([min(year_list)-5,max(year_list)+5], [3, 3], 'r--')\n",
    "\n",
    "                # plt.plot([min(year_list)-5,max(year_list)+5], [0.2,0.2], 'k:')\n",
    "                # plt.plot([min(year_list)-5,max(year_list)+5], [0.3,0.3], 'k:')\n",
    "                # plt.text(year_list[0]-4, 0.25 , 'The LOLE reported in National Grids Winter Outlook in 2021\\nand 2022 were 0.3 and 0.2 hrs/year.' , fontsize = 14 , color = 'k' , ha = 'left' )\n",
    "            plt.plot(sub_pd.index, sub_pd[col], color='dodgerblue')\n",
    "            plt.scatter(sub_pd.index, sub_pd[col], color='darkorange', marker='o')\n",
    "            # plt.title(case+' - '+col)\n",
    "            plt.ylabel('Hours')\n",
    "            plt.grid(True)\n",
    "            plt.xticks(year_list)\n",
    "            plt.xlim(min(year_list)-5,max(year_list)+5)\n",
    "            plt.savefig('../data/LOLE/'+case+'_'+col+'_'+re.sub(\"[^A-Z]\",\"\",scenario)+'.png', bbox_inches='tight', dpi=600)\n",
    "            plt.show()\n",
    "\n",
    "    for col in pd_plot.columns.tolist():\n",
    "        plt.figure(figsize=(10,4))\n",
    "        # plt.axes(yscale='log')\n",
    "        for case in pd_plot.index.get_level_values(0).drop_duplicates().tolist()[:-1]:\n",
    "            sub_pd = pd_plot.loc[case]\n",
    "            if case == 'Gas supply issues':\n",
    "                case = 'Gas power generation in Scotland unavailable'\n",
    "            if case == 'Largest offshore failure':\n",
    "                case = 'Offshore wind farm failures'  \n",
    "            plt.plot(sub_pd.index, sub_pd[col], marker='o', label=case)\n",
    "\n",
    "        # if col == 'lole_week':\n",
    "        #     plt.title('all_scenario - '+'lole')\n",
    "        # else:\n",
    "        #     plt.title('all_scenario - '+col)\n",
    "        # plt.title('all_scenario - '+col)\n",
    "\n",
    "        plt.ylabel('Hours')\n",
    "        plt.xticks(year_list)\n",
    "        plt.xlim(min(year_list)-5,max(year_list)+5)\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.savefig('../data/LOLE/all_scenario_'+col+'_'+re.sub(\"[^A-Z]\",\"\",scenario)+'.png', bbox_inches='tight', dpi=600)\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10,4))\n",
    "        # plt.axes(yscale='log')\n",
    "        for case in pd_plot.index.get_level_values(0).drop_duplicates().tolist()[:-1]:\n",
    "            sub_pd = pd_plot.loc[case]\n",
    "            if case == 'Gas supply issues':\n",
    "                case = 'Gas power generation in Scotland unavailable'\n",
    "            if case == 'Largest offshore failure':\n",
    "                case = 'Offshore wind farm failures'  \n",
    "            plt.plot(sub_pd.index, sub_pd[col], marker='o', label=case)\n",
    "        plt.plot([min(year_list)-5,max(year_list)+5], [3,3], 'r--', linewidth=1)\n",
    "        plt.plot([min(year_list)-5,max(year_list)+5], [0.108, 0.108], 'b--', linewidth=1)\n",
    "        # plt.text(year_list[0]-4, 2 , 'The current reliability standard for LOLE in GB\\nis set to no more than three hours a year.' , fontsize = 14 , color = 'k' , ha = 'left' )\n",
    "        \n",
    "        # if col == 'lole_week':\n",
    "        #     plt.title('all_scenario - '+'lole')\n",
    "        # else:\n",
    "        #     plt.title('all_scenario - '+col)\n",
    "        \n",
    "        plt.ylabel('Hours')\n",
    "        plt.xticks(year_list)\n",
    "        plt.xlim(min(year_list)-5,max(year_list)+5)\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.savefig('../data/LOLE/all_scenario_'+col+'_l_'+re.sub(\"[^A-Z]\",\"\",scenario)+'.png', bbox_inches='tight', dpi=600)\n",
    "        plt.show()\n",
    "        \n",
    "    for col in pd_plot_self.columns.tolist():\n",
    "        plt.figure(figsize=(10,4))\n",
    "        # plt.axes(yscale='log')\n",
    "        for case in pd_plot_self.index.get_level_values(0).drop_duplicates().tolist():\n",
    "            sub_pd = pd_plot_self.loc[case]\n",
    "            plt.plot(sub_pd.index, sub_pd[col], marker='o', label=case)\n",
    "        # plt.title('all_scenario - '+col + ' (self-sufficient)')\n",
    "        # plt.plot([min(year_list)-5,max(year_list)+5], [3, 3], 'r:')\n",
    "        # plt.plot([min(year_list)-5,max(year_list)+5], [0.108, 0.108], 'b:')\n",
    "        plt.xticks(year_list)\n",
    "        plt.xlim(min(year_list)-5,max(year_list)+5)\n",
    "        plt.legend()\n",
    "        plt.savefig('../data/LOLE/self_all_scenario'+'_'+col+'_'+re.sub(\"[^A-Z]\",\"\",scenario)+'.png', bbox_inches='tight', dpi=600)\n",
    "        plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(year_list, md_rate, color='dodgerblue')\n",
    "    plt.scatter(year_list, md_rate, color='darkorange', marker='o')\n",
    "    plt.title('De-rated Supply margin')\n",
    "    plt.xticks(year_list)\n",
    "    plt.xlim(min(year_list)-2,max(year_list)+2)\n",
    "    plt.gca().yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1,decimals=0))\n",
    "    plt.savefig('../data/LOLE/margin_demand.png', dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    cm = plt.get_cmap('gnuplot')\n",
    "    bottom = np.zeros(pd_de_rate.shape[1])\n",
    "    for i in range(pd_de_rate.shape[0]):\n",
    "        carrier = pd_de_rate.index.tolist()[i]\n",
    "        plt.bar(year_list, \n",
    "                pd_de_rate.loc[carrier].to_numpy(),\n",
    "                bottom=bottom,\n",
    "                # color=cm(.5+.5*(-1.)**i+(1.)**i*i/pd_de_rate.shape[0]),\n",
    "                label=carrier)\n",
    "        bottom += pd_de_rate.loc[carrier].to_numpy()\n",
    "    plt.title('De-rated Supply margin in relation to De-rated generation capacity ')\n",
    "    plt.xticks(year_list)\n",
    "    plt.xlim(min(year_list)-2,max(year_list)+2)\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "    plt.show()\n",
    "    pd_de_rate.to_csv('../data/LOLE/combi_de-rated_cap_types.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac30199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_sufficient_plot(scenario, year_list, system_reserve_requirment=1200):\n",
    "    all_lole_loop = pd.DataFrame()\n",
    "    pd_plot = pd.DataFrame(index=year_list)\n",
    "    for year in year_list:\n",
    "        lole_loop = pd.read_csv('../data/LOLE/lole_loop_'+str(year)+'_'+re.sub(\"[^A-Z]\",\"\", scenario)+'.csv', index_col=0)\n",
    "        lole_loop = lole_loop[['Self-sufficient', 'Self_Low RES power']].copy()\n",
    "        lole_loop.columns = [[year,year],lole_loop.columns.tolist()]\n",
    "        all_lole_loop = pd.concat([all_lole_loop, lole_loop], axis=1)\n",
    "\n",
    "    pd_plot['LOLE for Self-sufficient base case'] = all_lole_loop.loc[:,(slice(None), 'Self-sufficient')].loc[0,:].values\n",
    "    \n",
    "    # all_lole_loop.loc[:,(slice(None), 'Self-sufficient')]\n",
    "    index_1 = all_lole_loop.loc[:,(slice(None), 'Self-sufficient')].T.max()[all_lole_loop.loc[:,(slice(None), 'Self-sufficient')].T.max()<3].index[0]\n",
    "    pd_plot['Base case with additional '+str(index_1)+'MW firm capacity'] = all_lole_loop.loc[index_1,(slice(None), 'Self-sufficient')].values\n",
    "    index_2 = all_lole_loop.loc[:,(slice(None), 'Self-sufficient')].T.max()[all_lole_loop.loc[:,(slice(None), 'Self-sufficient')].T.max()<0.3].index[0]\n",
    "    pd_plot['Base case with additional '+str(index_2)+'MW firm capacity'] = all_lole_loop.loc[index_2,(slice(None), 'Self-sufficient')].values\n",
    "\n",
    "\n",
    "    for _ in range(len(year_list)):\n",
    "        if np.isnan(pd_plot['Base case with additional '+str(index_1)+'MW firm capacity'].values[_]):\n",
    "            year = year_list[_]\n",
    "            pd_cdf = pd.read_csv('../data/LOLE/cdf_'+str(year)+'_'+re.sub(\"[^A-Z]\",\"\",scenario)+'.csv', index_col=0)\n",
    "            xx = pd_cdf['xx']\n",
    "            yy = pd_cdf['yy']\n",
    "            net_demand = pd.read_csv('../data/LOLE/margin_demand_'+str(year)+'_'+re.sub(\"[^A-Z]\",\"\", scenario)+'.csv')['net_demand']\n",
    "            lolp = list()\n",
    "            for i in range(len(net_demand)):\n",
    "                lolp.append(yy[xx<net_demand[i]+system_reserve_requirment-index_1].sum())\n",
    "            lole = sum(lolp)\n",
    "            pd_plot.loc[year, 'Base case with additional '+str(index_1)+'MW firm capacity'] = lole\n",
    "            pd_plot.loc[year, 'Base case with additional '+str(index_2)+'MW firm capacity'] = lole\n",
    "        if np.isnan(pd_plot['Base case with additional '+str(index_2)+'MW firm capacity'].values[_]):\n",
    "            year = year_list[_]\n",
    "            pd_cdf = pd.read_csv('../data/LOLE/cdf_'+str(year)+'_'+re.sub(\"[^A-Z]\",\"\",scenario)+'.csv', index_col=0)\n",
    "            xx = pd_cdf['xx']\n",
    "            yy = pd_cdf['yy']\n",
    "            net_demand = pd.read_csv('../data/LOLE/margin_demand_'+str(year)+'_'+re.sub(\"[^A-Z]\",\"\", scenario)+'.csv')['net_demand']\n",
    "            lolp = list()\n",
    "            for i in range(len(net_demand)):\n",
    "                lolp.append(yy[xx<net_demand[i]+system_reserve_requirment-index_2].sum())\n",
    "            lole = sum(lolp)\n",
    "            pd_plot.loc[year, 'Base case with additional '+str(index_2)+'MW firm capacity'] = lole\n",
    "    \n",
    "    plt.figure(figsize=(10,4))\n",
    "    for col in pd_plot.columns.tolist():\n",
    "        plt.plot(pd_plot.index, pd_plot[col], marker='o', label=col)\n",
    "    plt.xticks(year_list)\n",
    "    plt.xlim(min(year_list)-5,max(year_list)+5)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.savefig('../data/LOLE/LOLE self-suffient.png', dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfc348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6123370",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf33af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    rate_table()\n",
    "\n",
    "    # scenario = 'Leading The Way'\n",
    "    # scenario = 'Consumer Transformation'\n",
    "    scenario = 'System Transformation'\n",
    "    # scenario = 'Steady Progression'\n",
    "\n",
    "    year_list = [2021, 2025, 2030, 2035, 2040, 2045]\n",
    "\n",
    "    import time\n",
    "    st = time.time()\n",
    "\n",
    "    # # # main(2020, scenario, demand_dataset='historical')\n",
    "    # main(2021, scenario)\n",
    "    # main(2025, scenario)\n",
    "    # # # # main(2025, scenario, nuclear=False)\n",
    "    # main(2030, scenario)\n",
    "    # main(2035, scenario)\n",
    "    # main(2040, scenario)\n",
    "    # main(2045, scenario)\n",
    "\n",
    "    main_plot(scenario, year_list)\n",
    "    self_sufficient_plot(scenario, year_list)\n",
    "\n",
    "    print(time.time() - st)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

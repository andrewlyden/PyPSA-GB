{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Network Constrained Linear Optimal Power Flow with Floating Wind & Marine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyPSA-GB can model the GB power system  by solving a network constrained Linear Optimal Power Flow (LOPF) problem. This notebook shows the example application of a future period, and disaggregates the results by novel offshore renewables: floating wind, wave power and tidal stream.  Tidal lagoon power is also disaggregated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "src_path = os.environ.get('PROJECT_SRC')\n",
    "os.chdir(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pypsa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import data_reader_writer\n",
    "import generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the required inputs for the LOPF: the start, end and year of simulation, and the timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv files for import\n",
    "start = '2050-06-01 00:00:00'\n",
    "end = '2050-06-01 23:30:00'\n",
    "# year of simulation\n",
    "year = int(start[0:4])\n",
    "# time step as fraction of hour\n",
    "time_step = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose from one of the National Grid Future Energy Scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = 'Leading The Way'\n",
    "# scenario = 'Consumer Transformation'\n",
    "# scenario = 'System Transformation'\n",
    "# scenario = 'Steady Progression'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a baseline year (from 2010-2020). The baseline year determines which historical load profile and weather dataset is used for the future year modelled. The National Grid FES modellers used 2012 as their baseline year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_baseline = 2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_reader_writer is a script written to read in data from the various sources and write csv files in the format required for populating a PyPSA network object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# floating wind TRUE/FALSE input...\n",
    "\n",
    "# if floating wind True, then set 'merge_generators=False', in data_writer function else set merge_generators=True\n",
    "\n",
    "# Setting merge_generators argument FALSE manually yields generators.csv with types and sites denoted. Excellent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s1100626\\Anaconda3\\envs\\PyPSA-GB\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:741: PerformanceWarning: Non-vectorized DateOffset being applied to Series or DatetimeIndex\n",
      "  warnings.warn(\n",
      "C:\\Users\\s1100626\\Anaconda3\\envs\\PyPSA-GB\\lib\\site-packages\\pandas\\core\\indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n",
      "C:\\Users\\s1100626\\Documents\\GitHub\\PyPSA-GB\\PyPSA-GB\\interconnectors.py:201: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  df_FES = df_FES[~df_FES.Variable.str.contains('(TWh)')]\n"
     ]
    }
   ],
   "source": [
    "data_reader_writer.data_writer(start, end, time_step, year, year_baseline=year_baseline,\n",
    "                               scenario=scenario, merge_generators=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pypsa.io:\n",
      "Importing PyPSA from older version of PyPSA than current version.\n",
      "Please read the release notes at https://pypsa.readthedocs.io/en/latest/release_notes.html\n",
      "carefully to prepare your network for import.\n",
      "Currently used PyPSA version [0, 19, 2], imported network file PyPSA version None.\n",
      "\n",
      "INFO:pypsa.components:Applying weightings to all columns of `snapshot_weightings`\n",
      "INFO:pypsa.io:Imported network LOPF_data has buses, generators, lines, links, loads, storage_units\n"
     ]
    }
   ],
   "source": [
    "network = pypsa.Network()\n",
    "\n",
    "network.import_from_csv_folder('LOPF_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lines need to be scaled up to accomadate for future generation, and specific analysis will be done on this in a later notebook.\n",
    "Note: interconnects are links in future, so don't need to be selective here (as was required in historical simulation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_factor = 4\n",
    "network.lines.s_max_pu *= contingency_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pypsa.linopf:Prepare linear problem\n",
      "INFO:pypsa.linopf:Total preparation time: 1.84s\n",
      "INFO:pypsa.linopf:Solve linear problem using Gurobi solver\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2022-05-19\n",
      "Error reading LP format file C:\\Users\\s1100626\\AppData\\Local\\Temp\\pypsa-problem-zf2jlg1v.lp at line 287887\n",
      "Unrecognized constraint RHS or sense\n",
      "Neighboring tokens: \" <= +nan c70230: +1.000000 x1230 <= +1.133519 \"\n",
      "\n",
      "Unable to read file\n"
     ]
    },
    {
     "ename": "GurobiError",
     "evalue": "Unable to read model",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mGurobiError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlopf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msnapshots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgurobi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpyomo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\PyPSA-GB\\lib\\site-packages\\pypsa\\components.py:660\u001b[0m, in \u001b[0;36mNetwork.lopf\u001b[1;34m(self, snapshots, pyomo, solver_name, solver_options, solver_logfile, formulation, keep_files, extra_functionality, multi_investment_periods, **kwargs)\u001b[0m\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m network_lopf(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 660\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnetwork_lopf_lowmem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\PyPSA-GB\\lib\\site-packages\\pypsa\\linopf.py:1241\u001b[0m, in \u001b[0;36mnetwork_lopf\u001b[1;34m(n, snapshots, solver_name, solver_logfile, extra_functionality, multi_investment_periods, skip_objective, skip_pre, extra_postprocessing, formulation, keep_references, keep_files, keep_shadowprices, solver_options, warmstart, store_basis, solver_dir)\u001b[0m\n\u001b[0;32m   1238\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolve linear problem using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msolver_name\u001b[38;5;241m.\u001b[39mtitle()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m solver\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1240\u001b[0m solve \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_and_read_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msolver_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproblem_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolution_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_logfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[43m            \u001b[49m\u001b[43msolver_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_basis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1244\u001b[0m status, termination_condition, variables_sol, constraints_dual, obj \u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keep_files:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\PyPSA-GB\\lib\\site-packages\\pypsa\\linopt.py:992\u001b[0m, in \u001b[0;36mrun_and_read_gurobi\u001b[1;34m(n, problem_fn, solution_fn, solver_logfile, solver_options, warmstart, store_basis)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;66;03m# disable logging for this part, as gurobi output is doubled otherwise\u001b[39;00m\n\u001b[0;32m    990\u001b[0m logging\u001b[38;5;241m.\u001b[39mdisable(\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m--> 992\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43mgurobipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solver_options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    994\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m solver_options\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32msrc\\gurobipy\\gurobi.pxi:3575\u001b[0m, in \u001b[0;36mgurobipy.read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\gurobipy\\gurobi.pxi:90\u001b[0m, in \u001b[0;36mgurobipy.gurobi.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mGurobiError\u001b[0m: Unable to read model"
     ]
    }
   ],
   "source": [
    "network.lopf(network.snapshots, solver_name=\"gurobi\", pyomo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power output by generation type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the generators by the carrier, and print their summed power outputs over the simulation period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(network.generators) \n",
    "    \n",
    "# saving the dataframe \n",
    "df.to_csv('network.generators.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(network.generators_t.p) \n",
    "    \n",
    "# # saving the dataframe \n",
    "# df.to_csv('network.generators_t.p.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(network.generators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read network.generators\n",
    "# in network.generators, offshore wind is already grouped by BUS - this means that new carrier type is required...?\n",
    "# find floating wind sites: Generator = I, E, F, G, NE8, NE7, E3, E2, NE1, E1, NE2, NE3, NE6, N2, N3\n",
    "# https://datagy.io/pandas-replace-values/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_by_carrier = network.generators_t.p.groupby(\n",
    "    network.generators.carrier, axis=1).sum()\n",
    "\n",
    "storage_by_carrier = network.storage_units_t.p.groupby(\n",
    "    network.storage_units.carrier, axis=1).sum()\n",
    "\n",
    "# to show on graph set the negative storage values to zero\n",
    "storage_by_carrier[storage_by_carrier < 0] = 0\n",
    "\n",
    "p_by_carrier = pd.concat([p_by_carrier, storage_by_carrier], axis=1)\n",
    "\n",
    "print(network.links_t.p0)\n",
    "imp = network.links_t.p0.copy()\n",
    "imp[imp < 0] = 0\n",
    "imp['Interconnectors Import'] = imp.sum(axis=1)\n",
    "interconnector_import = imp[['Interconnectors Import']]\n",
    "print(interconnector_import)\n",
    "\n",
    "p_by_carrier = pd.concat([p_by_carrier, interconnector_import], axis=1)\n",
    "\n",
    "exp = network.links_t.p0.copy()\n",
    "exp[exp > 0] = 0\n",
    "exp['Interconnectors Export'] = exp.sum(axis=1)\n",
    "interconnector_export = exp[['Interconnectors Export']]\n",
    "print(interconnector_export)\n",
    "\n",
    "# group biomass stuff\n",
    "p_by_carrier['Biomass'] = (\n",
    "    p_by_carrier['Biomass (dedicated)'] + p_by_carrier['Biomass (co-firing)'] +\n",
    "    p_by_carrier['Landfill Gas'] + p_by_carrier['Anaerobic Digestion'] +\n",
    "    p_by_carrier['Sewage Sludge Digestion'])\n",
    "\n",
    "# rename the hydro bit\n",
    "p_by_carrier = p_by_carrier.rename(\n",
    "    columns={'Large Hydro': 'Hydro'})\n",
    "p_by_carrier = p_by_carrier.rename(\n",
    "    columns={'Interconnector': 'Interconnectors Import'})\n",
    "\n",
    "p_by_carrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_by_type = network.generators_t.p.groupby(\n",
    "    network.generators.type, axis=1).sum()\n",
    "\n",
    "storage_by_type = network.storage_units_t.p.groupby(\n",
    "    network.storage_units.type, axis=1).sum()\n",
    "\n",
    "# to show on graph set the negative storage values to zero\n",
    "storage_by_type[storage_by_type < 0] = 0\n",
    "\n",
    "p_by_type = pd.concat([p_by_type, storage_by_type], axis=1)\n",
    "\n",
    "print(network.links_t.p0)\n",
    "imp = network.links_t.p0.copy()\n",
    "imp[imp < 0] = 0\n",
    "imp['Interconnectors Import'] = imp.sum(axis=1)\n",
    "interconnector_import = imp[['Interconnectors Import']]\n",
    "print(interconnector_import)\n",
    "\n",
    "p_by_type = pd.concat([p_by_type, interconnector_import], axis=1)\n",
    "\n",
    "exp = network.links_t.p0.copy()\n",
    "exp[exp > 0] = 0\n",
    "exp['Interconnectors Export'] = exp.sum(axis=1)\n",
    "interconnector_export = exp[['Interconnectors Export']]\n",
    "print(interconnector_export)\n",
    "\n",
    "# group biomass stuff\n",
    "p_by_type['Biomass'] = (\n",
    "    p_by_type['Biomass (dedicated)'] + p_by_type['Biomass (co-firing)'] +\n",
    "    p_by_type['Landfill Gas'] + p_by_type['Anaerobic Digestion'] +\n",
    "    p_by_type['Sewage Sludge Digestion'])\n",
    "\n",
    "# rename the hydro bit\n",
    "p_by_type = p_by_type.rename(\n",
    "    columns={'Large Hydro': 'Hydro'})\n",
    "p_by_type = p_by_type.rename(\n",
    "    columns={'Interconnector': 'Interconnectors Import'})\n",
    "\n",
    "p_by_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(p_by_carrier) \n",
    "    \n",
    "# saving the dataframe \n",
    "df.to_csv('p_by_carrier.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(p_by_type) \n",
    "    \n",
    "# saving the dataframe \n",
    "df.to_csv('p_by_type.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph the power output of the different generation types..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read in csv containing generation types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['Nuclear', 'Biomass',\n",
    "        'EfW Incineration', 'Oil', 'Natural Gas',\n",
    "        'Hydrogen', 'CCS Gas', 'CCS Biomass','Interconnectors Import',\n",
    "        'Pumped Storage Hydroelectric', 'Hydro',\n",
    "        'Battery', 'Compressed Air', 'Liquid Air',\n",
    "        'Wind Offshore', 'Wind Onshore', 'Solar Photovoltaics',\n",
    "        'Tidal lagoon', 'Tidal stream', 'Wave power', 'Unmet Load'\n",
    "        ]\n",
    "\n",
    "# types alphabetically are:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "p_by_carrier = p_by_carrier[cols]\n",
    "\n",
    "# edited such that all sources are shown regardless of power contribution\n",
    "p_by_carrier.drop(\n",
    "    (p_by_carrier.max()[p_by_carrier.max() < 0.0]).index,\n",
    "    axis=1, inplace=True)\n",
    "\n",
    "\n",
    "colors = {'Coal': 'dimgrey',\n",
    "          'Diesel/Gas oil': 'lightgrey',\n",
    "          'Diesel/gas Diesel/Gas oil': 'lightgrey',\n",
    "          'Oil': 'red',\n",
    "          'Unmet Load': 'black',\n",
    "          'Anaerobic Digestion': 'darkgoldenrod',\n",
    "          'EfW Incineration': 'chocolate',\n",
    "          'Sewage Sludge Digestion': 'saddlebrown',\n",
    "          'Landfill Gas': 'olive',\n",
    "          'Biomass (dedicated)': 'olivedrab',\n",
    "          'Biomass (co-firing)': 'yellowgreen',\n",
    "          'Biomass': 'greenyellow',\n",
    "          'CCS Biomass': 'darkolivegreen',\n",
    "          'Interconnectors Import': 'palevioletred',\n",
    "          'Interconnectors Export': 'crimson',          \n",
    "          'Sour gas': 'darkred',\n",
    "          'Natural Gas': 'coral',\n",
    "          'CCS Gas': 'lightcoral',\n",
    "          'Hydrogen': 'paleturquoise',\n",
    "          'Nuclear': 'lime',\n",
    "          'Wave power': 'steelblue',\n",
    "          'Tidal lagoon': 'mediumblue',\n",
    "          'Tidal stream': 'midnightblue',\n",
    "          'Hydro': 'teal',\n",
    "          'Large Hydro': 'darkturquoise',\n",
    "          'Small Hydro': 'turquoise',\n",
    "          'Pumped Storage Hydroelectric': 'deepskyblue',\n",
    "          'Battery': 'mediumorchid',\n",
    "          'Compressed Air': 'plum',\n",
    "          'Liquid Air': 'thistle',\n",
    "          'Floating Wind': 'royalblue',\n",
    "          'Wind Offshore': 'cornflowerblue',\n",
    "          'Wind Onshore': 'mediumseagreen',\n",
    "          'Solar Photovoltaics': 'yellow'}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(15,10)\n",
    "(p_by_carrier / 1e3).plot(\n",
    "    kind='area', ax=ax, linewidth=0,\n",
    "    color=[colors[col] for col in p_by_carrier.columns])\n",
    "\n",
    "# stacked area plot of negative values, prepend column names with '_' such that they don't appear in the legend\n",
    "(interconnector_export / 1e3).plot.area(ax=ax, stacked=True, linewidth=0.)\n",
    "# rescale the y axis\n",
    "ax.set_ylim([(interconnector_export / 1e3).sum(axis=1).min(), (p_by_carrier / 1e3).sum(axis=1).max()])\n",
    "\n",
    "# Shrink current axis's height by 10% on the bottom\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                 box.width, box.height * 0.9])\n",
    "\n",
    "# Put a legend below current axis\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "\n",
    "ax.set_ylabel('GW')\n",
    "\n",
    "ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculating emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the emissions from each carrier according to the power output..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plotting storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph the pumped hydro dispatch and state of charge..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(15,10)\n",
    "\n",
    "p_storage = network.storage_units_t.p.sum(axis=1)\n",
    "state_of_charge = network.storage_units_t.state_of_charge.sum(axis=1)\n",
    "p_storage.plot(label=\"Pumped hydro dispatch\", ax=ax, linewidth=3)\n",
    "state_of_charge.plot(label=\"State of charge\", ax=ax, linewidth=3)\n",
    "\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"MWh\")\n",
    "ax.set_xlabel(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting line loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the line loading stats and graph..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = network.snapshots[139]\n",
    "\n",
    "print(\"With the linear load flow, there is the following per unit loading:\")\n",
    "loading = network.lines_t.p0.loc[now] / network.lines.s_nom\n",
    "loading.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "fig.set_size_inches(15, 17)\n",
    "\n",
    "network.plot(ax=ax, line_colors=abs(loading), line_cmap=plt.cm.jet, title=\"Line loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting locational marginal prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "fig.set_size_inches(20, 10)\n",
    "\n",
    "network.plot(ax=ax, line_widths=pd.Series(0.5, network.lines.index))\n",
    "plt.hexbin(network.buses.x, network.buses.y,\n",
    "           gridsize=20,\n",
    "           C=network.buses_t.marginal_price.loc[now],\n",
    "           cmap=plt.cm.jet)\n",
    "\n",
    "# for some reason the colorbar only works with graphs plt.plot\n",
    "# and must be attached plt.colorbar\n",
    "\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('Locational Marginal Price (Â£/MWh)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.buses_t.marginal_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting curtailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier = \"Wind Onshore\"\n",
    "\n",
    "capacity = network.generators.groupby(\"carrier\").sum().at[carrier, \"p_nom\"]\n",
    "p_available = network.generators_t.p_max_pu.multiply(network.generators[\"p_nom\"])\n",
    "p_available_by_carrier = p_available.groupby(network.generators.carrier, axis=1).sum()\n",
    "p_curtailed_by_carrier = p_available_by_carrier - p_by_carrier\n",
    "p_df = pd.DataFrame({carrier + \" available\": p_available_by_carrier[carrier],\n",
    "                     carrier + \" dispatched\": p_by_carrier[carrier],\n",
    "                     carrier + \" curtailed\": p_curtailed_by_carrier[carrier]})\n",
    "\n",
    "p_df[carrier + \" capacity\"] = capacity\n",
    "p_df[\"Wind Onshore curtailed\"][p_df[\"Wind Onshore curtailed\"] < 0.] = 0.\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(15,10)\n",
    "p_df[[carrier + \" dispatched\", carrier + \" curtailed\"]].plot(kind=\"area\", ax=ax, linewidth=0)\n",
    "p_df[[carrier + \" available\", carrier + \" capacity\"]].plot(ax=ax, linewidth=0)\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"Power [MW]\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyPSA-GB",
   "language": "python",
   "name": "pypsa-gb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
